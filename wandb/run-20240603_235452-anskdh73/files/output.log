Proportion of positive examples: 0.00010072860356579256
pad token id is none
finishing tokeninzing
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/03/2024 23:55:06 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 14%|█▍        | 4/28 [00:00<00:00, 26.95it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 25%|██▌       | 7/28 [00:00<00:00, 23.32it/s]
 25%|██▌       | 7/28 [00:00<00:00, 23.32it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:00, 22.22it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 46%|████▋     | 13/28 [00:00<00:00, 21.52it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 57%|█████▋    | 16/28 [00:00<00:00, 21.34it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 68%|██████▊   | 19/28 [00:00<00:00, 21.16it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▊  | 22/28 [00:01<00:00, 21.04it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 89%|████████▉ | 25/28 [00:01<00:00, 21.01it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
100%|██████████| 28/28 [00:01<00:00, 21.44it/s]
06/03/2024 23:55:09 - INFO - trainers - ***** Running training *****
06/03/2024 23:55:09 - INFO - trainers -   Num examples = 29,783
06/03/2024 23:55:09 - INFO - trainers -   Num Epochs = 1
06/03/2024 23:55:09 - INFO - trainers -   Instantaneous batch size per device = 32
06/03/2024 23:55:09 - INFO - trainers -   Total train batch size (w. parallel, distributed & accumulation) = 32
06/03/2024 23:55:09 - INFO - trainers -   Gradient Accumulation steps = 1
06/03/2024 23:55:09 - INFO - trainers -   Total optimization steps = 931
06/03/2024 23:55:09 - INFO - trainers -   Number of trainable parameters = 12,288
  0%|          | 0/931 [00:00<?, ?it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 1/931 [00:00<02:03,  7.52it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:00, 22.28it/s]
balanced data AUC before train
 {'eval_loss': 0.47799980640411377, 'eval_roc_auc': 0.4986370716510903, 'eval_runtime': 1.6766, 'eval_samples_per_second': 520.102, 'eval_steps_per_second': 16.701}
create optimizer for AUC maximization
self optimizer is none
None
AdamW
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 1/931 [00:01<02:03,  7.52it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 2/931 [00:01<14:06,  1.10it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▊  | 22/28 [00:01<00:00, 21.07it/s]
{'eval_loss': 0.48940807580947876, 'eval_roc_auc': 0.5010577165950998, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.749, 'eval_steps_per_second': 20.799, 'epoch': 0.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.4959266781806946, 'eval_roc_auc': 0.5024732676601835, 'eval_runtime': 1.3346, 'eval_samples_per_second': 653.375, 'eval_steps_per_second': 20.98, 'epoch': 0.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 2/931 [00:02<14:06,  1.10it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 3/931 [00:03<17:50,  1.15s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 3/931 [00:04<17:50,  1.15s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 4/931 [00:04<19:34,  1.27s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5001024603843689, 'eval_roc_auc': 0.5038993432685022, 'eval_runtime': 1.3337, 'eval_samples_per_second': 653.797, 'eval_steps_per_second': 20.993, 'epoch': 0.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 4/931 [00:05<19:34,  1.27s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 5/931 [00:05<20:34,  1.33s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5029257535934448, 'eval_roc_auc': 0.505341205691673, 'eval_runtime': 1.3419, 'eval_samples_per_second': 649.834, 'eval_steps_per_second': 20.866, 'epoch': 0.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5048466324806213, 'eval_roc_auc': 0.5068199040161657, 'eval_runtime': 1.3402, 'eval_samples_per_second': 650.669, 'eval_steps_per_second': 20.893, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 5/931 [00:07<20:34,  1.33s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 6/931 [00:07<21:08,  1.37s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 6/931 [00:08<21:08,  1.37s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 7/931 [00:08<21:24,  1.39s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5061032176017761, 'eval_roc_auc': 0.5082301928096321, 'eval_runtime': 1.3198, 'eval_samples_per_second': 660.706, 'eval_steps_per_second': 21.215, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 7/931 [00:10<21:24,  1.39s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 8/931 [00:10<21:35,  1.40s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 46%|████▋     | 13/28 [00:00<00:00, 21.84it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5069390535354614, 'eval_roc_auc': 0.5092405489601751, 'eval_runtime': 1.3215, 'eval_samples_per_second': 659.832, 'eval_steps_per_second': 21.187, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 8/931 [00:11<21:35,  1.40s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 9/931 [00:11<21:42,  1.41s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 89%|████████▉ | 25/28 [00:01<00:00, 21.02it/s]
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5074917078018188, 'eval_roc_auc': 0.5101246105919003, 'eval_runtime': 1.3235, 'eval_samples_per_second': 658.861, 'eval_steps_per_second': 21.156, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5078759789466858, 'eval_roc_auc': 0.5108560663467205, 'eval_runtime': 1.3287, 'eval_samples_per_second': 656.302, 'eval_steps_per_second': 21.074, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 10/931 [00:14<21:48,  1.42s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 11/931 [00:14<21:53,  1.43s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 25%|██▌       | 7/28 [00:00<00:00, 23.75it/s]
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`
{'eval_loss': 0.5081489086151123, 'eval_roc_auc': 0.511729603435211, 'eval_runtime': 1.3318, 'eval_samples_per_second': 654.773, 'eval_steps_per_second': 21.025, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 11/931 [00:15<21:53,  1.43s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|▏         | 12/931 [00:15<21:55,  1.43s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`
{'eval_loss': 0.5083436965942383, 'eval_roc_auc': 0.5124110676096657, 'eval_runtime': 1.329, 'eval_samples_per_second': 656.15, 'eval_steps_per_second': 21.069, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
  1%|▏         | 13/931 [00:17<21:57,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|▏         | 13/931 [00:18<21:57,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 14/931 [00:18<21:57,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]
  1%|▏         | 13/931 [00:17<21:57,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5086035132408142, 'eval_roc_auc': 0.51372400437821, 'eval_runtime': 1.3306, 'eval_samples_per_second': 655.327, 'eval_steps_per_second': 21.043, 'epoch': 0.01}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 14/931 [00:20<21:57,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 15/931 [00:20<21:58,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5086893439292908, 'eval_roc_auc': 0.5142923297128904, 'eval_runtime': 1.3341, 'eval_samples_per_second': 653.605, 'eval_steps_per_second': 20.987, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
  2%|▏         | 15/931 [00:21<21:58,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
  2%|▏         | 16/931 [00:21<21:57,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 15/931 [00:21<21:58,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5087527632713318, 'eval_roc_auc': 0.5148343436894839, 'eval_runtime': 1.3332, 'eval_samples_per_second': 654.078, 'eval_steps_per_second': 21.002, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5088038444519043, 'eval_roc_auc': 0.5154342426538688, 'eval_runtime': 1.3352, 'eval_samples_per_second': 653.069, 'eval_steps_per_second': 20.97, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 17/931 [00:24<21:57,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 18/931 [00:24<22:00,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 15/931 [00:21<21:58,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5088428854942322, 'eval_roc_auc': 0.5158762734697314, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.641, 'eval_steps_per_second': 20.828, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
  2%|▏         | 18/931 [00:25<22:00,  1.45s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 19/931 [00:26<21:59,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5088738799095154, 'eval_roc_auc': 0.5163288288288288, 'eval_runtime': 1.3363, 'eval_samples_per_second': 652.565, 'eval_steps_per_second': 20.954, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 20/931 [00:28<21:56,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 21/931 [00:28<21:53,  1.44s/it]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5088992118835449, 'eval_roc_auc': 0.5168024332743959, 'eval_runtime': 1.3303, 'eval_samples_per_second': 655.509, 'eval_steps_per_second': 21.048, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089205503463745, 'eval_roc_auc': 0.5173181358929022, 'eval_runtime': 1.3313, 'eval_samples_per_second': 654.977, 'eval_steps_per_second': 21.031, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 21/931 [00:30<21:53,  1.44s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 22/931 [00:30<21:51,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089375972747803, 'eval_roc_auc': 0.5178917234992001, 'eval_runtime': 1.3318, 'eval_samples_per_second': 654.77, 'eval_steps_per_second': 21.025, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▊  | 22/28 [00:01<00:00, 20.97it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089321136474609, 'eval_roc_auc': 0.5179864443883135, 'eval_runtime': 1.3358, 'eval_samples_per_second': 652.804, 'eval_steps_per_second': 20.962, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089272856712341, 'eval_roc_auc': 0.5180390671044877, 'eval_runtime': 1.3356, 'eval_samples_per_second': 652.904, 'eval_steps_per_second': 20.965, 'epoch': 0.02}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  3%|▎         | 24/931 [00:34<21:50,  1.45s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  3%|▎         | 25/931 [00:34<21:48,  1.44s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089227557182312, 'eval_roc_auc': 0.5181548370800707, 'eval_runtime': 1.3354, 'eval_samples_per_second': 653.002, 'eval_steps_per_second': 20.968, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089187622070312, 'eval_roc_auc': 0.518286393870506, 'eval_runtime': 1.3355, 'eval_samples_per_second': 652.946, 'eval_steps_per_second': 20.966, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  3%|▎         | 27/931 [00:38<21:47,  1.45s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089152455329895, 'eval_roc_auc': 0.5183705902163847, 'eval_runtime': 1.3415, 'eval_samples_per_second': 650.024, 'eval_steps_per_second': 20.872, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089123249053955, 'eval_roc_auc': 0.5183969015744717, 'eval_runtime': 1.3395, 'eval_samples_per_second': 650.97, 'eval_steps_per_second': 20.903, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:00, 22.17it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089133977890015, 'eval_roc_auc': 0.5186652774269597, 'eval_runtime': 1.3358, 'eval_samples_per_second': 652.787, 'eval_steps_per_second': 20.961, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 79%|███████▊  | 22/28 [00:01<00:00, 20.88it/s]adding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
 79%|███████▊  | 22/28 [00:01<00:00, 20.88it/s]adding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089144110679626, 'eval_roc_auc': 0.5190494232550308, 'eval_runtime': 1.3404, 'eval_samples_per_second': 650.531, 'eval_steps_per_second': 20.889, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089164972305298, 'eval_roc_auc': 0.5197914035530857, 'eval_runtime': 1.3626, 'eval_samples_per_second': 639.955, 'eval_steps_per_second': 20.549, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.508917510509491, 'eval_roc_auc': 0.5200966153068957, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.328, 'eval_steps_per_second': 20.818, 'epoch': 0.03}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089185237884521, 'eval_roc_auc': 0.5205018102214364, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.238, 'eval_steps_per_second': 20.847, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089198350906372, 'eval_roc_auc': 0.5209070051359771, 'eval_runtime': 1.3415, 'eval_samples_per_second': 650.037, 'eval_steps_per_second': 20.873, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089224576950073, 'eval_roc_auc': 0.5212490527911089, 'eval_runtime': 1.3395, 'eval_samples_per_second': 650.977, 'eval_steps_per_second': 20.903, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089249014854431, 'eval_roc_auc': 0.5215016418287447, 'eval_runtime': 1.3426, 'eval_samples_per_second': 649.479, 'eval_steps_per_second': 20.855, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089271664619446, 'eval_roc_auc': 0.5217437063231456, 'eval_runtime': 1.3405, 'eval_samples_per_second': 650.505, 'eval_steps_per_second': 20.888, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089291930198669, 'eval_roc_auc': 0.5219173612865202, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.652, 'eval_steps_per_second': 20.828, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089311003684998, 'eval_roc_auc': 0.5221252210154079, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.591, 'eval_steps_per_second': 20.858, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.508934497833252, 'eval_roc_auc': 0.5224541129914961, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.423, 'eval_steps_per_second': 20.853, 'epoch': 0.04}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089412927627563, 'eval_roc_auc': 0.5231013724004379, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.811, 'eval_steps_per_second': 20.833, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089443922042847, 'eval_roc_auc': 0.5233223878083691, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.046, 'eval_steps_per_second': 20.841, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089473128318787, 'eval_roc_auc': 0.5236802222783531, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.545, 'eval_steps_per_second': 20.825, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089501738548279, 'eval_roc_auc': 0.5238591395133452, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.579, 'eval_steps_per_second': 20.858, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089528560638428, 'eval_roc_auc': 0.5239959585753978, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.502, 'eval_steps_per_second': 20.791, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.508955180644989, 'eval_roc_auc': 0.524201187168477, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.009, 'eval_steps_per_second': 20.84, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089573860168457, 'eval_roc_auc': 0.5243643175886167, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.884, 'eval_steps_per_second': 20.836, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089594721794128, 'eval_roc_auc': 0.5245432348236087, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.788, 'eval_steps_per_second': 20.833, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089613795280457, 'eval_roc_auc': 0.5246800538856613, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.455, 'eval_steps_per_second': 20.822, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089631676673889, 'eval_roc_auc': 0.5248247663551402, 'eval_runtime': 1.3425, 'eval_samples_per_second': 649.527, 'eval_steps_per_second': 20.856, 'epoch': 0.05}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.``
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.``
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089661478996277, 'eval_roc_auc': 0.5251273469731413, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.447, 'eval_steps_per_second': 20.822, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089676380157471, 'eval_roc_auc': 0.5251799696893155, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.057, 'eval_steps_per_second': 20.809, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089690089225769, 'eval_roc_auc': 0.5252325924054897, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.639, 'eval_steps_per_second': 20.764, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.508970320224762, 'eval_roc_auc': 0.5253115264797508, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.256, 'eval_steps_per_second': 20.783, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.508971631526947, 'eval_roc_auc': 0.5254483455418035, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.419, 'eval_steps_per_second': 20.789, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089728236198425, 'eval_roc_auc': 0.5255114928012125, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.214, 'eval_steps_per_second': 20.846, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
  6%|▋         | 59/931 [01:25<21:09,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
  6%|▋         | 59/931 [01:25<21:09,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089738965034485, 'eval_roc_auc': 0.5255641155173866, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.88, 'eval_steps_per_second': 20.803, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.508975088596344, 'eval_roc_auc': 0.5256220005051782, 'eval_runtime': 1.3483, 'eval_samples_per_second': 646.717, 'eval_steps_per_second': 20.766, 'epoch': 0.06}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089762210845947, 'eval_roc_auc': 0.525711459122674, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.275, 'eval_steps_per_second': 20.784, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089774131774902, 'eval_roc_auc': 0.5257588195672308, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.744, 'eval_steps_per_second': 20.831, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.508979856967926, 'eval_roc_auc': 0.5261745390250063, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.133, 'eval_steps_per_second': 20.812, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089812874794006, 'eval_roc_auc': 0.52655342258146, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.91, 'eval_steps_per_second': 20.837, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089826583862305, 'eval_roc_auc': 0.5269007325082091, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.741, 'eval_steps_per_second': 20.799, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089840888977051, 'eval_roc_auc': 0.527205944262019, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.906, 'eval_steps_per_second': 20.836, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089855194091797, 'eval_roc_auc': 0.5274216973983329, 'eval_runtime': 1.3488, 'eval_samples_per_second': 646.497, 'eval_steps_per_second': 20.759, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5089869499206543, 'eval_roc_auc': 0.5275743032752378, 'eval_runtime': 1.3492, 'eval_samples_per_second': 646.311, 'eval_steps_per_second': 20.753, 'epoch': 0.07}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.```
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.```
{'eval_loss': 0.5089881420135498, 'eval_roc_auc': 0.5277137534730992, 'eval_runtime': 1.3711, 'eval_samples_per_second': 635.984, 'eval_steps_per_second': 20.422, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089893341064453, 'eval_roc_auc': 0.5279479245600741, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.458, 'eval_steps_per_second': 20.79, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089904069900513, 'eval_roc_auc': 0.528137366338301, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.444, 'eval_steps_per_second': 20.789, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089913606643677, 'eval_roc_auc': 0.5282478740422666, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.59, 'eval_steps_per_second': 20.794, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089922547340393, 'eval_roc_auc': 0.5284952008082849, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.39, 'eval_steps_per_second': 20.788, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089930295944214, 'eval_roc_auc': 0.5286583312284246, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.58, 'eval_steps_per_second': 20.826, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5089939832687378, 'eval_roc_auc': 0.5288319861917993, 'eval_runtime': 1.3491, 'eval_samples_per_second': 646.333, 'eval_steps_per_second': 20.754, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
  8%|▊         | 77/931 [01:51<20:45,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
  8%|▊         | 77/931 [01:51<20:45,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.508994996547699, 'eval_roc_auc': 0.5289530184389997, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.254, 'eval_steps_per_second': 20.816, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5089977383613586, 'eval_roc_auc': 0.5295634419466195, 'eval_runtime': 1.3505, 'eval_samples_per_second': 645.665, 'eval_steps_per_second': 20.732, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090001225471497, 'eval_roc_auc': 0.5303027911088658, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.473, 'eval_steps_per_second': 20.823, 'epoch': 0.08}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090022087097168, 'eval_roc_auc': 0.530757977603772, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.63, 'eval_steps_per_second': 20.795, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090040564537048, 'eval_roc_auc': 0.5312105329628694, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.576, 'eval_steps_per_second': 20.794, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090057253837585, 'eval_roc_auc': 0.5317525469394628, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.245, 'eval_steps_per_second': 20.847, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090071558952332, 'eval_roc_auc': 0.5321156436810642, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.935, 'eval_steps_per_second': 20.805, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090084671974182, 'eval_roc_auc': 0.5325366254104572, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.55, 'eval_steps_per_second': 20.825, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090097784996033, 'eval_roc_auc': 0.5328470994358845, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.569, 'eval_steps_per_second': 20.826, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090108513832092, 'eval_roc_auc': 0.5332496632146164, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.165, 'eval_steps_per_second': 20.813, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090120434761047, 'eval_roc_auc': 0.5336469647217311, 'eval_runtime': 1.3511, 'eval_samples_per_second': 645.413, 'eval_steps_per_second': 20.724, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.``
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.``
{'eval_loss': 0.5090131759643555, 'eval_roc_auc': 0.5339627010187757, 'eval_runtime': 1.3939, 'eval_samples_per_second': 625.579, 'eval_steps_per_second': 20.087, 'epoch': 0.09}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090144276618958, 'eval_roc_auc': 0.5344099941062558, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.413, 'eval_steps_per_second': 20.788, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.``
{'eval_loss': 0.5090155005455017, 'eval_roc_auc': 0.5348125578849878, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.2, 'eval_steps_per_second': 20.782, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090164542198181, 'eval_roc_auc': 0.5352677443798939, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.843, 'eval_steps_per_second': 20.802, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090172290802002, 'eval_roc_auc': 0.5355834806769387, 'eval_runtime': 1.3511, 'eval_samples_per_second': 645.42, 'eval_steps_per_second': 20.724, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090180039405823, 'eval_roc_auc': 0.535830807442957, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.254, 'eval_steps_per_second': 20.783, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090187191963196, 'eval_roc_auc': 0.5360833964805927, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.282, 'eval_steps_per_second': 20.784, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090193152427673, 'eval_roc_auc': 0.5363780836911678, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.904, 'eval_steps_per_second': 20.804, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 10%|█         | 96/931 [02:19<20:18,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
 10%|█         | 96/931 [02:19<20:18,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090198516845703, 'eval_roc_auc': 0.5365885745558643, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.109, 'eval_steps_per_second': 20.811, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090203285217285, 'eval_roc_auc': 0.5367569672476215, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.948, 'eval_steps_per_second': 20.838, 'epoch': 0.1}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 10%|█         | 96/931 [02:19<20:18,  1.46s/itGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090207457542419, 'eval_roc_auc': 0.5370042940136398, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.215, 'eval_steps_per_second': 20.846, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090211629867554, 'eval_roc_auc': 0.5371568998905447, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.51, 'eval_steps_per_second': 20.792, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090216398239136, 'eval_roc_auc': 0.5373042434958323, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.825, 'eval_steps_per_second': 20.802, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090219974517822, 'eval_roc_auc': 0.537556832533468, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.565, 'eval_steps_per_second': 20.825, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090223550796509, 'eval_roc_auc': 0.5376989138671382, 'eval_runtime': 1.3457, 'eval_samples_per_second': 648.005, 'eval_steps_per_second': 20.808, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090227127075195, 'eval_roc_auc': 0.5377936347562515, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.679, 'eval_steps_per_second': 20.797, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090230703353882, 'eval_roc_auc': 0.5378830933737476, 'eval_runtime': 1.3478, 'eval_samples_per_second': 647.0, 'eval_steps_per_second': 20.775, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090234279632568, 'eval_roc_auc': 0.5379830765344784, 'eval_runtime': 1.3497, 'eval_samples_per_second': 646.071, 'eval_steps_per_second': 20.745, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090237259864807, 'eval_roc_auc': 0.5381146333249137, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.809, 'eval_steps_per_second': 20.833, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090242028236389, 'eval_roc_auc': 0.5382988128315231, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.236, 'eval_steps_per_second': 20.847, 'epoch': 0.11}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090245008468628, 'eval_roc_auc': 0.5383882714490191, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.829, 'eval_steps_per_second': 20.802, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.5384777300665151, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.541, 'eval_steps_per_second': 20.825, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090250968933105, 'eval_roc_auc': 0.538540877325924, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.708, 'eval_steps_per_second': 20.798, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5386619095731245, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.434, 'eval_steps_per_second': 20.821, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090256929397583, 'eval_roc_auc': 0.5387724172770901, 'eval_runtime': 1.3481, 'eval_samples_per_second': 646.846, 'eval_steps_per_second': 20.77, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090259909629822, 'eval_roc_auc': 0.5388671381662036, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.068, 'eval_steps_per_second': 20.81, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 12%|█▏        | 114/931 [02:45<19:48,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
 12%|█▏        | 114/931 [02:45<19:48,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090262293815613, 'eval_roc_auc': 0.53893554769723, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.75, 'eval_steps_per_second': 20.831, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090264678001404, 'eval_roc_auc': 0.5390250063147259, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.434, 'eval_steps_per_second': 20.821, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090267062187195, 'eval_roc_auc': 0.5391092026606046, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.641, 'eval_steps_per_second': 20.828, 'epoch': 0.12}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090269446372986, 'eval_roc_auc': 0.5391933990064831, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.859, 'eval_steps_per_second': 20.835, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090271234512329, 'eval_roc_auc': 0.5392302349078049, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.808, 'eval_steps_per_second': 20.833, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090273022651672, 'eval_roc_auc': 0.5393091689820662, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.723, 'eval_steps_per_second': 20.831, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090275406837463, 'eval_roc_auc': 0.5393933653279448, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.891, 'eval_steps_per_second': 20.772, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090277194976807, 'eval_roc_auc': 0.5394880862170581, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.442, 'eval_steps_per_second': 20.822, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509027898311615, 'eval_roc_auc': 0.5395301843899974, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.62, 'eval_steps_per_second': 20.795, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090280771255493, 'eval_roc_auc': 0.5396564789088154, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.553, 'eval_steps_per_second': 20.825, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090281367301941, 'eval_roc_auc': 0.5397091016249894, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.184, 'eval_steps_per_second': 20.813, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090283155441284, 'eval_roc_auc': 0.5397459375263114, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.575, 'eval_steps_per_second': 20.762, 'epoch': 0.13}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090284943580627, 'eval_roc_auc': 0.5397564620695462, 'eval_runtime': 1.3474, 'eval_samples_per_second': 647.181, 'eval_steps_per_second': 20.781, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090285539627075, 'eval_roc_auc': 0.5397459375263114, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.908, 'eval_steps_per_second': 20.837, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.``
{'eval_loss': 0.5090287327766418, 'eval_roc_auc': 0.5397775111560158, 'eval_runtime': 1.3489, 'eval_samples_per_second': 646.444, 'eval_steps_per_second': 20.757, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090288519859314, 'eval_roc_auc': 0.5397880356992506, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.006, 'eval_steps_per_second': 20.775, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509028971195221, 'eval_roc_auc': 0.5398090847857203, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.342, 'eval_steps_per_second': 20.818, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.```
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.5398617075018943, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.68, 'eval_steps_per_second': 20.829, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 14%|█▍        | 133/931 [03:12<19:22,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 14%|█▍        | 133/931 [03:12<19:22,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090292096138, 'eval_roc_auc': 0.5398774943167466, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.039, 'eval_steps_per_second': 20.809, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090292692184448, 'eval_roc_auc': 0.5399301170329207, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.532, 'eval_steps_per_second': 20.792, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090293884277344, 'eval_roc_auc': 0.5399774774774775, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.345, 'eval_steps_per_second': 20.818, 'epoch': 0.14}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090295076370239, 'eval_roc_auc': 0.53997221520586, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.732, 'eval_steps_per_second': 20.831, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090296268463135, 'eval_roc_auc': 0.5399880020207123, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.349, 'eval_steps_per_second': 20.819, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090296268463135, 'eval_roc_auc': 0.5400195756504168, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.652, 'eval_steps_per_second': 20.828, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509029746055603, 'eval_roc_auc': 0.5400406247368864, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.359, 'eval_steps_per_second': 20.819, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090298652648926, 'eval_roc_auc': 0.5400248379220342, 'eval_runtime': 6.2916, 'eval_samples_per_second': 138.597, 'eval_steps_per_second': 4.45, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090299248695374, 'eval_roc_auc': 0.5400301001936516, 'eval_runtime': 1.3384, 'eval_samples_per_second': 651.523, 'eval_steps_per_second': 20.92, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090300440788269, 'eval_roc_auc': 0.5401774437989391, 'eval_runtime': 1.3396, 'eval_samples_per_second': 650.949, 'eval_steps_per_second': 20.902, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090302228927612, 'eval_roc_auc': 0.5403247874042266, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.441, 'eval_steps_per_second': 20.854, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090291500091553, 'eval_roc_auc': 0.5404195082933401, 'eval_runtime': 1.3391, 'eval_samples_per_second': 651.169, 'eval_steps_per_second': 20.909, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090282559394836, 'eval_roc_auc': 0.5406299991580366, 'eval_runtime': 1.3413, 'eval_samples_per_second': 650.093, 'eval_steps_per_second': 20.875, 'epoch': 0.15}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090274214744568, 'eval_roc_auc': 0.5407826050349415, 'eval_runtime': 1.3407, 'eval_samples_per_second': 650.404, 'eval_steps_per_second': 20.885, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090265274047852, 'eval_roc_auc': 0.5408352277511155, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.14, 'eval_steps_per_second': 20.78, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090258121490479, 'eval_roc_auc': 0.5408562768375852, 'eval_runtime': 1.352, 'eval_samples_per_second': 644.966, 'eval_steps_per_second': 20.71, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090250968933105, 'eval_roc_auc': 0.5408510145659678, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.415, 'eval_steps_per_second': 20.789, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 16%|█▌        | 150/931 [03:41<19:31,  1.50s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 16%|█▌        | 150/931 [03:41<19:31,  1.50s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.509024441242218, 'eval_roc_auc': 0.540929948640229, 'eval_runtime': 1.3532, 'eval_samples_per_second': 644.403, 'eval_steps_per_second': 20.692, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509023904800415, 'eval_roc_auc': 0.5409983581712553, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.2, 'eval_steps_per_second': 20.782, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090233087539673, 'eval_roc_auc': 0.5410720299738991, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.784, 'eval_steps_per_second': 20.833, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090228915214539, 'eval_roc_auc': 0.5412088490359518, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.063, 'eval_steps_per_second': 20.809, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090224146842957, 'eval_roc_auc': 0.5412298981224215, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.585, 'eval_steps_per_second': 20.826, 'epoch': 0.16}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509022057056427, 'eval_roc_auc': 0.5412930453818304, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.283, 'eval_steps_per_second': 20.816, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090218186378479, 'eval_roc_auc': 0.5414088153574135, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.625, 'eval_steps_per_second': 20.763, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509021520614624, 'eval_roc_auc': 0.5414824871600572, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.199, 'eval_steps_per_second': 20.846, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090214014053345, 'eval_roc_auc': 0.5415403721478488, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.764, 'eval_steps_per_second': 20.8, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090212821960449, 'eval_roc_auc': 0.5416035194072577, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.425, 'eval_steps_per_second': 20.789, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090212225914001, 'eval_roc_auc': 0.5416982402963711, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.726, 'eval_steps_per_second': 20.831, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090228915214539, 'eval_roc_auc': 0.5442241306727288, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.606, 'eval_steps_per_second': 20.795, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090236067771912, 'eval_roc_auc': 0.5455186494906121, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.999, 'eval_steps_per_second': 20.775, 'epoch': 0.17}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090243220329285, 'eval_roc_auc': 0.5468657910246696, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.103, 'eval_steps_per_second': 20.811, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090250372886658, 'eval_roc_auc': 0.5477603771996296, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.488, 'eval_steps_per_second': 20.791, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090255737304688, 'eval_roc_auc': 0.5487075860907636, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.93, 'eval_steps_per_second': 20.773, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509026050567627, 'eval_roc_auc': 0.5498126631304201, 'eval_runtime': 1.3481, 'eval_samples_per_second': 646.847, 'eval_steps_per_second': 20.77, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 18%|█▊        | 167/931 [04:07<18:35,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 18%|█▊        | 167/931 [04:07<18:35,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090265870094299, 'eval_roc_auc': 0.5507177738486149, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.632, 'eval_steps_per_second': 20.796, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090269446372986, 'eval_roc_auc': 0.5516334091100445, 'eval_runtime': 1.3494, 'eval_samples_per_second': 646.232, 'eval_steps_per_second': 20.751, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 18%|█▊        | 167/931 [04:07<18:35,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090273022651672, 'eval_roc_auc': 0.552328028963543, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.111, 'eval_steps_per_second': 20.811, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090276598930359, 'eval_roc_auc': 0.5531752546939463, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.303, 'eval_steps_per_second': 20.785, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090280175209045, 'eval_roc_auc': 0.5540014313378799, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.082, 'eval_steps_per_second': 20.778, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090282559394836, 'eval_roc_auc': 0.5547013134629957, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.847, 'eval_steps_per_second': 20.802, 'epoch': 0.18}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090284943580627, 'eval_roc_auc': 0.555127557464006, 'eval_runtime': 1.3503, 'eval_samples_per_second': 645.771, 'eval_steps_per_second': 20.736, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090287327766418, 'eval_roc_auc': 0.5554485560326682, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.055, 'eval_steps_per_second': 20.777, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090290307998657, 'eval_roc_auc': 0.555995832280879, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.3, 'eval_steps_per_second': 20.785, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090292096138, 'eval_roc_auc': 0.5563694535657152, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.026, 'eval_steps_per_second': 20.808, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090293884277344, 'eval_roc_auc': 0.5567851730234907, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.257, 'eval_steps_per_second': 20.816, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``.`
{'eval_loss': 0.5090295672416687, 'eval_roc_auc': 0.557185105666414, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.975, 'eval_steps_per_second': 20.807, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509029746055603, 'eval_roc_auc': 0.557632398753894, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.434, 'eval_steps_per_second': 20.789, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``.`
{'eval_loss': 0.5090299248695374, 'eval_roc_auc': 0.5580007577671129, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.149, 'eval_steps_per_second': 20.812, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``.`
{'eval_loss': 0.5090300440788269, 'eval_roc_auc': 0.5584533131262103, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.807, 'eval_steps_per_second': 20.833, 'epoch': 0.19}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``.`
{'eval_loss': 0.509030282497406, 'eval_roc_auc': 0.558724320114507, 'eval_runtime': 1.3461, 'eval_samples_per_second': 647.781, 'eval_steps_per_second': 20.8, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090304017066956, 'eval_roc_auc': 0.5590453186831692, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.102, 'eval_steps_per_second': 20.811, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090305209159851, 'eval_roc_auc': 0.559305801128231, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.13, 'eval_steps_per_second': 20.812, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090306401252747, 'eval_roc_auc': 0.5595531278942494, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.527, 'eval_steps_per_second': 20.824, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090307593345642, 'eval_roc_auc': 0.5597425696724763, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.657, 'eval_steps_per_second': 20.828, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090308785438538, 'eval_roc_auc': 0.5599109623642333, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.344, 'eval_steps_per_second': 20.818, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090309381484985, 'eval_roc_auc': 0.5600793550559906, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.882, 'eval_steps_per_second': 20.804, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090310573577881, 'eval_roc_auc': 0.5600740927843731, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.304, 'eval_steps_per_second': 20.785, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090311765670776, 'eval_roc_auc': 0.5602319609328954, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.94, 'eval_steps_per_second': 20.773, 'epoch': 0.2}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090312957763672, 'eval_roc_auc': 0.5603161572787742, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.865, 'eval_steps_per_second': 20.835, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509031355381012, 'eval_roc_auc': 0.5604582386124441, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.947, 'eval_steps_per_second': 20.806, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090314745903015, 'eval_roc_auc': 0.5604635008840616, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.693, 'eval_steps_per_second': 20.83, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090315341949463, 'eval_roc_auc': 0.5605266481434706, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.717, 'eval_steps_per_second': 20.83, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090315937995911, 'eval_roc_auc': 0.5605476972299402, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.228, 'eval_steps_per_second': 20.847, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090317130088806, 'eval_roc_auc': 0.5605897954028796, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.998, 'eval_steps_per_second': 20.807, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090317726135254, 'eval_roc_auc': 0.5606424181190536, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.335, 'eval_steps_per_second': 20.818, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090318322181702, 'eval_roc_auc': 0.5606739917487581, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.364, 'eval_steps_per_second': 20.787, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090319514274597, 'eval_roc_auc': 0.560737139008167, 'eval_runtime': 1.349, 'eval_samples_per_second': 646.428, 'eval_steps_per_second': 20.757, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090320706367493, 'eval_roc_auc': 0.5607844994527237, 'eval_runtime': 1.3498, 'eval_samples_per_second': 646.006, 'eval_steps_per_second': 20.743, 'epoch': 0.21}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090320706367493, 'eval_roc_auc': 0.5608213353540457, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.793, 'eval_steps_per_second': 20.769, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090321898460388, 'eval_roc_auc': 0.5608581712553675, 'eval_runtime': 1.354, 'eval_samples_per_second': 644.006, 'eval_steps_per_second': 20.679, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090322494506836, 'eval_roc_auc': 0.560863433526985, 'eval_runtime': 1.3621, 'eval_samples_per_second': 640.201, 'eval_steps_per_second': 20.557, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090323090553284, 'eval_roc_auc': 0.5608739580702198, 'eval_runtime': 1.5569, 'eval_samples_per_second': 560.095, 'eval_steps_per_second': 17.985, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090323686599731, 'eval_roc_auc': 0.5609055316999242, 'eval_runtime': 1.3813, 'eval_samples_per_second': 631.302, 'eval_steps_per_second': 20.271, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090324282646179, 'eval_roc_auc': 0.5609213185147764, 'eval_runtime': 1.3827, 'eval_samples_per_second': 630.673, 'eval_steps_per_second': 20.251, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090324878692627, 'eval_roc_auc': 0.560942367601246, 'eval_runtime': 1.3689, 'eval_samples_per_second': 637.02, 'eval_steps_per_second': 20.455, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090325474739075, 'eval_roc_auc': 0.5609581544160984, 'eval_runtime': 1.3824, 'eval_samples_per_second': 630.807, 'eval_steps_per_second': 20.255, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509032666683197, 'eval_roc_auc': 0.560979203502568, 'eval_runtime': 1.5288, 'eval_samples_per_second': 570.372, 'eval_steps_per_second': 18.315, 'epoch': 0.22}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090327262878418, 'eval_roc_auc': 0.5610186705396986, 'eval_runtime': 1.4394, 'eval_samples_per_second': 605.82, 'eval_steps_per_second': 19.453, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090327858924866, 'eval_roc_auc': 0.5610581375768292, 'eval_runtime': 1.4487, 'eval_samples_per_second': 601.936, 'eval_steps_per_second': 19.328, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090328454971313, 'eval_roc_auc': 0.5610949734781511, 'eval_runtime': 1.4694, 'eval_samples_per_second': 593.459, 'eval_steps_per_second': 19.056, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090329051017761, 'eval_roc_auc': 0.5610897112065336, 'eval_runtime': 1.3586, 'eval_samples_per_second': 641.858, 'eval_steps_per_second': 20.61, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090329647064209, 'eval_roc_auc': 0.5611054980213859, 'eval_runtime': 1.3966, 'eval_samples_per_second': 624.388, 'eval_steps_per_second': 20.049, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090330839157104, 'eval_roc_auc': 0.5611160225646208, 'eval_runtime': 1.4096, 'eval_samples_per_second': 618.612, 'eval_steps_per_second': 19.864, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090331435203552, 'eval_roc_auc': 0.5611475961943251, 'eval_runtime': 1.428, 'eval_samples_per_second': 610.644, 'eval_steps_per_second': 19.608, 'epoch': 0.23}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090332627296448, 'eval_roc_auc': 0.5611686452807949, 'eval_runtime': 1.6827, 'eval_samples_per_second': 518.225, 'eval_steps_per_second': 16.64, 'epoch': 0.23}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090332627296448, 'eval_roc_auc': 0.5612002189104994, 'eval_runtime': 1.3754, 'eval_samples_per_second': 634.008, 'eval_steps_per_second': 20.358, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090333223342896, 'eval_roc_auc': 0.5611949566388819, 'eval_runtime': 1.4181, 'eval_samples_per_second': 614.895, 'eval_steps_per_second': 19.744, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090334415435791, 'eval_roc_auc': 0.5611949566388819, 'eval_runtime': 1.3939, 'eval_samples_per_second': 625.562, 'eval_steps_per_second': 20.087, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090335011482239, 'eval_roc_auc': 0.5612633661699082, 'eval_runtime': 1.3962, 'eval_samples_per_second': 624.553, 'eval_steps_per_second': 20.054, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090335607528687, 'eval_roc_auc': 0.5612975709354214, 'eval_runtime': 1.3786, 'eval_samples_per_second': 632.536, 'eval_steps_per_second': 20.311, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090336203575134, 'eval_roc_auc': 0.5612896775279953, 'eval_runtime': 1.3991, 'eval_samples_per_second': 623.251, 'eval_steps_per_second': 20.013, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509033739566803, 'eval_roc_auc': 0.561310726614465, 'eval_runtime': 1.4347, 'eval_samples_per_second': 607.812, 'eval_steps_per_second': 19.517, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509033739566803, 'eval_roc_auc': 0.5612896775279953, 'eval_runtime': 1.3577, 'eval_samples_per_second': 642.261, 'eval_steps_per_second': 20.623, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.5613317757009346, 'eval_runtime': 1.3662, 'eval_samples_per_second': 638.283, 'eval_steps_per_second': 20.495, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.561363349330639, 'eval_runtime': 1.352, 'eval_samples_per_second': 644.986, 'eval_steps_per_second': 20.711, 'epoch': 0.24}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 25%|██▍       | 229/931 [05:40<17:23,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 25%|██▍       | 229/931 [05:40<17:23,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090339183807373, 'eval_roc_auc': 0.5613896606887261, 'eval_runtime': 1.353, 'eval_samples_per_second': 644.502, 'eval_steps_per_second': 20.695, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090340375900269, 'eval_roc_auc': 0.5614107097751958, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.866, 'eval_steps_per_second': 20.803, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 25%|██▍       | 229/931 [05:40<17:23,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090340375900269, 'eval_roc_auc': 0.561426496590048, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.342, 'eval_steps_per_second': 20.818, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090340971946716, 'eval_roc_auc': 0.5614317588616654, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.945, 'eval_steps_per_second': 20.773, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090341567993164, 'eval_roc_auc': 0.5614317588616654, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.508, 'eval_steps_per_second': 20.792, 'epoch': 0.25}
before update
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509034276008606, 'eval_roc_auc': 0.5614212343184306, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.373, 'eval_steps_per_second': 20.787, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509034276008606, 'eval_roc_auc': 0.561400185231961, 'eval_runtime': 1.3504, 'eval_samples_per_second': 645.729, 'eval_steps_per_second': 20.734, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343356132507, 'eval_roc_auc': 0.5614107097751957, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.952, 'eval_steps_per_second': 20.806, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090343952178955, 'eval_roc_auc': 0.5614080786393871, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.45, 'eval_steps_per_second': 20.79, 'epoch': 0.25}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090344548225403, 'eval_roc_auc': 0.561426496590048, 'eval_runtime': 1.3492, 'eval_samples_per_second': 646.311, 'eval_steps_per_second': 20.753, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090345144271851, 'eval_roc_auc': 0.561452807948135, 'eval_runtime': 1.3483, 'eval_samples_per_second': 646.755, 'eval_steps_per_second': 20.767, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090345144271851, 'eval_roc_auc': 0.5614843815778395, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.808, 'eval_steps_per_second': 20.769, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090345740318298, 'eval_roc_auc': 0.561515955207544, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.248, 'eval_steps_per_second': 20.783, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.5615370042940138, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.366, 'eval_steps_per_second': 20.787, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.5615370042940138, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.466, 'eval_steps_per_second': 20.79, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090347528457642, 'eval_roc_auc': 0.5615580533804833, 'eval_runtime': 1.3496, 'eval_samples_per_second': 646.107, 'eval_steps_per_second': 20.747, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090348124504089, 'eval_roc_auc': 0.5615738401953355, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.942, 'eval_steps_per_second': 20.838, 'epoch': 0.26}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.5615948892818052, 'eval_runtime': 1.3489, 'eval_samples_per_second': 646.462, 'eval_steps_per_second': 20.758, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 27%|██▋       | 248/931 [06:07<16:36,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 27%|██▋       | 248/931 [06:07<16:36,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.561623831775701, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.627, 'eval_steps_per_second': 20.795, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090349316596985, 'eval_roc_auc': 0.5616369874547446, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.854, 'eval_steps_per_second': 20.803, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 27%|██▋       | 248/931 [06:07<16:36,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509035050868988, 'eval_roc_auc': 0.5616396185905532, 'eval_runtime': 1.3474, 'eval_samples_per_second': 647.156, 'eval_steps_per_second': 20.78, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509035050868988, 'eval_roc_auc': 0.5616475119979792, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.635, 'eval_steps_per_second': 20.764, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090351104736328, 'eval_roc_auc': 0.5616527742695968, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.728, 'eval_steps_per_second': 20.799, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090351104736328, 'eval_roc_auc': 0.5616527742695967, 'eval_runtime': 1.3507, 'eval_samples_per_second': 645.593, 'eval_steps_per_second': 20.73, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.5616475119979792, 'eval_runtime': 1.3496, 'eval_samples_per_second': 646.121, 'eval_steps_per_second': 20.747, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090352296829224, 'eval_roc_auc': 0.5616632988128315, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.06, 'eval_steps_per_second': 20.809, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090352296829224, 'eval_roc_auc': 0.561658036541214, 'eval_runtime': 1.3506, 'eval_samples_per_second': 645.652, 'eval_steps_per_second': 20.732, 'epoch': 0.27}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090352892875671, 'eval_roc_auc': 0.5616632988128315, 'eval_runtime': 1.3484, 'eval_samples_per_second': 646.716, 'eval_steps_per_second': 20.766, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090353488922119, 'eval_roc_auc': 0.5617369706154752, 'eval_runtime': 1.3487, 'eval_samples_per_second': 646.549, 'eval_steps_per_second': 20.761, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090353488922119, 'eval_roc_auc': 0.5617790687884145, 'eval_runtime': 1.3495, 'eval_samples_per_second': 646.162, 'eval_steps_per_second': 20.748, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090354681015015, 'eval_roc_auc': 0.5618001178748843, 'eval_runtime': 1.3494, 'eval_samples_per_second': 646.211, 'eval_steps_per_second': 20.75, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090355277061462, 'eval_roc_auc': 0.5618053801465016, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.806, 'eval_steps_per_second': 20.769, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090355277061462, 'eval_roc_auc': 0.5618369537762061, 'eval_runtime': 1.3488, 'eval_samples_per_second': 646.499, 'eval_steps_per_second': 20.759, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509035587310791, 'eval_roc_auc': 0.5618343226403973, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.99, 'eval_steps_per_second': 20.775, 'epoch': 0.28}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090356469154358, 'eval_roc_auc': 0.5618580028626757, 'eval_runtime': 1.3558, 'eval_samples_per_second': 643.141, 'eval_steps_per_second': 20.651, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.5618843142207628, 'eval_runtime': 1.3495, 'eval_samples_per_second': 646.186, 'eval_steps_per_second': 20.749, 'epoch': 0.28}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090357661247253, 'eval_roc_auc': 0.561963248295024, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.583, 'eval_steps_per_second': 20.762, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090358853340149, 'eval_roc_auc': 0.5620106087395808, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.298, 'eval_steps_per_second': 20.785, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090358853340149, 'eval_roc_auc': 0.5620474446409025, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.594, 'eval_steps_per_second': 20.762, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090359449386597, 'eval_roc_auc': 0.5620948050854593, 'eval_runtime': 1.3517, 'eval_samples_per_second': 645.09, 'eval_steps_per_second': 20.714, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090360045433044, 'eval_roc_auc': 0.5620842805422244, 'eval_runtime': 1.3575, 'eval_samples_per_second': 642.37, 'eval_steps_per_second': 20.627, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090360641479492, 'eval_roc_auc': 0.5621579523448683, 'eval_runtime': 1.3717, 'eval_samples_per_second': 635.714, 'eval_steps_per_second': 20.413, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509036123752594, 'eval_roc_auc': 0.5622368864191294, 'eval_runtime': 1.3524, 'eval_samples_per_second': 644.76, 'eval_steps_per_second': 20.703, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090361833572388, 'eval_roc_auc': 0.5622289930117033, 'eval_runtime': 1.3488, 'eval_samples_per_second': 646.512, 'eval_steps_per_second': 20.76, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090361833572388, 'eval_roc_auc': 0.5622631977772166, 'eval_runtime': 1.3487, 'eval_samples_per_second': 646.545, 'eval_steps_per_second': 20.761, 'epoch': 0.29}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090362429618835, 'eval_roc_auc': 0.5622631977772165, 'eval_runtime': 1.3492, 'eval_samples_per_second': 646.331, 'eval_steps_per_second': 20.754, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090362429618835, 'eval_roc_auc': 0.5622631977772166, 'eval_runtime': 1.3474, 'eval_samples_per_second': 647.151, 'eval_steps_per_second': 20.78, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 30%|██▉       | 277/931 [06:50<15:55,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 30%|██▉       | 277/931 [06:50<15:55,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090363025665283, 'eval_roc_auc': 0.5622526732339816, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.764, 'eval_steps_per_second': 20.8, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090364217758179, 'eval_roc_auc': 0.5622526732339815, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.143, 'eval_steps_per_second': 20.812, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 30%|██▉       | 277/931 [06:50<15:55,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364217758179, 'eval_roc_auc': 0.562321082765008, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.756, 'eval_steps_per_second': 20.8, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364813804626, 'eval_roc_auc': 0.5623421318514776, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.128, 'eval_steps_per_second': 20.811, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090365409851074, 'eval_roc_auc': 0.5626262945188178, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.23, 'eval_steps_per_second': 20.815, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090366005897522, 'eval_roc_auc': 0.5629262440010103, 'eval_runtime': 6.0238, 'eval_samples_per_second': 144.76, 'eval_steps_per_second': 4.648, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509036660194397, 'eval_roc_auc': 0.5632577671129072, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.059, 'eval_steps_per_second': 20.809, 'epoch': 0.3}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367197990417, 'eval_roc_auc': 0.5634840447924561, 'eval_runtime': 1.3402, 'eval_samples_per_second': 650.658, 'eval_steps_per_second': 20.893, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367794036865, 'eval_roc_auc': 0.5637103224720047, 'eval_runtime': 1.3419, 'eval_samples_per_second': 649.847, 'eval_steps_per_second': 20.867, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090368390083313, 'eval_roc_auc': 0.5638629283489096, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.588, 'eval_steps_per_second': 20.794, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090368986129761, 'eval_roc_auc': 0.5641365664730151, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.026, 'eval_steps_per_second': 20.84, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090369582176208, 'eval_roc_auc': 0.5643575818809464, 'eval_runtime': 1.3403, 'eval_samples_per_second': 650.625, 'eval_steps_per_second': 20.892, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090370178222656, 'eval_roc_auc': 0.5645417613875559, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.429, 'eval_steps_per_second': 20.853, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.5648101372400438, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.34, 'eval_steps_per_second': 20.818, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.564915382672392, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.062, 'eval_steps_per_second': 20.809, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090372562408447, 'eval_roc_auc': 0.5649837922034184, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.804, 'eval_steps_per_second': 20.833, 'epoch': 0.31}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090372562408447, 'eval_roc_auc': 0.5651153489938536, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.475, 'eval_steps_per_second': 20.823, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090373158454895, 'eval_roc_auc': 0.56518375852488, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.3, 'eval_steps_per_second': 20.785, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090373158454895, 'eval_roc_auc': 0.5652311189694368, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.655, 'eval_steps_per_second': 20.828, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.5653047907720805, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.873, 'eval_steps_per_second': 20.835, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.5653837248463417, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.848, 'eval_steps_per_second': 20.802, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509037435054779, 'eval_roc_auc': 0.5653732003031069, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.82, 'eval_steps_per_second': 20.834, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.5653889871179592, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.247, 'eval_steps_per_second': 20.847, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.5653942493895765, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.149, 'eval_steps_per_second': 20.844, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090375542640686, 'eval_roc_auc': 0.565425823019281, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.4, 'eval_steps_per_second': 20.788, 'epoch': 0.32}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090376138687134, 'eval_roc_auc': 0.5654942325503074, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.584, 'eval_steps_per_second': 20.826, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090376138687134, 'eval_roc_auc': 0.5655573798097162, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.517, 'eval_steps_per_second': 20.824, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.5656152647975078, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.613, 'eval_steps_per_second': 20.827, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.565667887513682, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.119, 'eval_steps_per_second': 20.779, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.5656836743285342, 'eval_runtime': 1.3494, 'eval_samples_per_second': 646.197, 'eval_steps_per_second': 20.749, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 33%|███▎      | 308/931 [07:39<15:07,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 33%|███▎      | 308/931 [07:39<15:07,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.5657310347730908, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.598, 'eval_steps_per_second': 20.859, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.5657678706744127, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.842, 'eval_steps_per_second': 20.834, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.5658020754399259, 'eval_runtime': 1.3429, 'eval_samples_per_second': 649.36, 'eval_steps_per_second': 20.851, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.5658047065757346, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.147, 'eval_steps_per_second': 20.812, 'epoch': 0.33}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.5658625915635261, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.26, 'eval_steps_per_second': 20.848, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.5659257388229351, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.949, 'eval_steps_per_second': 20.806, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.5659415256377873, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.199, 'eval_steps_per_second': 20.814, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509037971496582, 'eval_roc_auc': 0.5659573124526396, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.472, 'eval_steps_per_second': 20.823, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509037971496582, 'eval_roc_auc': 0.565962574724257, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.942, 'eval_steps_per_second': 20.805, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090380311012268, 'eval_roc_auc': 0.5659783615391092, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.841, 'eval_steps_per_second': 20.834, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090380311012268, 'eval_roc_auc': 0.5659994106255789, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.006, 'eval_steps_per_second': 20.84, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090380907058716, 'eval_roc_auc': 0.5659994106255789, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.177, 'eval_steps_per_second': 20.845, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090381503105164, 'eval_roc_auc': 0.5660099351688137, 'eval_runtime': 1.3426, 'eval_samples_per_second': 649.468, 'eval_steps_per_second': 20.854, 'epoch': 0.34}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090381503105164, 'eval_roc_auc': 0.5660441399343269, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.385, 'eval_steps_per_second': 20.82, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090381503105164, 'eval_roc_auc': 0.5660625578849877, 'eval_runtime': 1.3497, 'eval_samples_per_second': 646.061, 'eval_steps_per_second': 20.745, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090382099151611, 'eval_roc_auc': 0.5660783446998401, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.181, 'eval_steps_per_second': 20.845, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090382695198059, 'eval_roc_auc': 0.5660941315146923, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.963, 'eval_steps_per_second': 20.806, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 35%|███▌      | 326/931 [08:06<14:40,  1.45s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 35%|███▌      | 326/931 [08:06<14:40,  1.45s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090382695198059, 'eval_roc_auc': 0.5661309674160142, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.882, 'eval_steps_per_second': 20.836, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090383291244507, 'eval_roc_auc': 0.566141491959249, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.013, 'eval_steps_per_second': 20.84, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.5661467542308664, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.326, 'eval_steps_per_second': 20.818, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.5661678033173361, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.332, 'eval_steps_per_second': 20.786, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.5661730655889534, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.703, 'eval_steps_per_second': 20.83, 'epoch': 0.35}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.5661993769470405, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.627, 'eval_steps_per_second': 20.827, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090384483337402, 'eval_roc_auc': 0.5662256883051277, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.193, 'eval_steps_per_second': 20.814, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.566212532626084, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.228, 'eval_steps_per_second': 20.815, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.5662256883051275, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.721, 'eval_steps_per_second': 20.798, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.5662519996632147, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.838, 'eval_steps_per_second': 20.834, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.5662756798854929, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.312, 'eval_steps_per_second': 20.817, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.5662914667003451, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.604, 'eval_steps_per_second': 20.827, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.5663046223793888, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.954, 'eval_steps_per_second': 20.806, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.5662993601077714, 'eval_runtime': 1.3434, 'eval_samples_per_second': 649.104, 'eval_steps_per_second': 20.843, 'epoch': 0.36}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386271476746, 'eval_roc_auc': 0.5663151469226235, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.102, 'eval_steps_per_second': 20.811, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.5663151469226235, 'eval_runtime': 1.3538, 'eval_samples_per_second': 644.098, 'eval_steps_per_second': 20.682, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.5663256714658583, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.918, 'eval_steps_per_second': 20.837, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.5663361960090932, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.651, 'eval_steps_per_second': 20.796, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 37%|███▋      | 344/931 [08:32<14:15,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 37%|███▋      | 344/931 [08:32<14:15,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.5663598762313716, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.872, 'eval_steps_per_second': 20.835, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.5663625073671803, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.306, 'eval_steps_per_second': 20.817, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 37%|███▋      | 344/931 [08:32<14:15,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.5663309337374758, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.794, 'eval_steps_per_second': 20.833, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090388059616089, 'eval_roc_auc': 0.5663361960090932, 'eval_runtime': 1.3489, 'eval_samples_per_second': 646.47, 'eval_steps_per_second': 20.758, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090388059616089, 'eval_roc_auc': 0.5663519828239455, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.014, 'eval_steps_per_second': 20.84, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090388059616089, 'eval_roc_auc': 0.5663782941820326, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.983, 'eval_steps_per_second': 20.807, 'epoch': 0.37}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.5663888187252673, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.456, 'eval_steps_per_second': 20.822, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090389251708984, 'eval_roc_auc': 0.5663967121326934, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.553, 'eval_steps_per_second': 20.825, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090389251708984, 'eval_roc_auc': 0.5663940809968847, 'eval_runtime': 1.349, 'eval_samples_per_second': 646.384, 'eval_steps_per_second': 20.755, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090389251708984, 'eval_roc_auc': 0.5664046055401195, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.172, 'eval_steps_per_second': 20.813, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090389847755432, 'eval_roc_auc': 0.5664098678117371, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.926, 'eval_steps_per_second': 20.837, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090380907058716, 'eval_roc_auc': 0.5657468215879431, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.951, 'eval_steps_per_second': 20.838, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090371966362, 'eval_roc_auc': 0.565362675759872, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.602, 'eval_steps_per_second': 20.859, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090363025665283, 'eval_roc_auc': 0.5648838090426875, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.554, 'eval_steps_per_second': 20.825, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090354084968567, 'eval_roc_auc': 0.5645101877578513, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.153, 'eval_steps_per_second': 20.844, 'epoch': 0.38}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090345144271851, 'eval_roc_auc': 0.564047107855519, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.221, 'eval_steps_per_second': 20.847, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090336799621582, 'eval_roc_auc': 0.5638155679043529, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.037, 'eval_steps_per_second': 20.809, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090328454971313, 'eval_roc_auc': 0.5634314220762819, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.915, 'eval_steps_per_second': 20.837, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090320706367493, 'eval_roc_auc': 0.5631104235076198, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.848, 'eval_steps_per_second': 20.835, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509031355381012, 'eval_roc_auc': 0.5628630967416014, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.001, 'eval_steps_per_second': 20.839, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 39%|███▉      | 364/931 [09:00<13:44,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 39%|███▉      | 364/931 [09:00<13:44,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090306401252747, 'eval_roc_auc': 0.5625789340742611, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.14, 'eval_steps_per_second': 20.812, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090299844741821, 'eval_roc_auc': 0.5624605329628695, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.258, 'eval_steps_per_second': 20.848, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090293884277344, 'eval_roc_auc': 0.5622526732339816, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.928, 'eval_steps_per_second': 20.837, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090287923812866, 'eval_roc_auc': 0.5621053296286941, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.499, 'eval_steps_per_second': 20.823, 'epoch': 0.39}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090282559394836, 'eval_roc_auc': 0.5621211164435463, 'eval_runtime': 1.3487, 'eval_samples_per_second': 646.57, 'eval_steps_per_second': 20.761, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090278387069702, 'eval_roc_auc': 0.561963248295024, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.345, 'eval_steps_per_second': 20.818, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090274214744568, 'eval_roc_auc': 0.5618422160478235, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.019, 'eval_steps_per_second': 20.84, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090270638465881, 'eval_roc_auc': 0.5618211669613539, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.388, 'eval_steps_per_second': 20.788, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090267062187195, 'eval_roc_auc': 0.5617317083438579, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.891, 'eval_steps_per_second': 20.836, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090264081954956, 'eval_roc_auc': 0.5617211838006231, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.68, 'eval_steps_per_second': 20.829, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090261101722717, 'eval_roc_auc': 0.5615843647385703, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.94, 'eval_steps_per_second': 20.838, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090259313583374, 'eval_roc_auc': 0.5614738570346047, 'eval_runtime': 1.3621, 'eval_samples_per_second': 640.204, 'eval_steps_per_second': 20.557, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090258717536926, 'eval_roc_auc': 0.561489643849457, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.051, 'eval_steps_per_second': 20.809, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090256929397583, 'eval_roc_auc': 0.5614475456765177, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.296, 'eval_steps_per_second': 20.817, 'epoch': 0.4}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090256333351135, 'eval_roc_auc': 0.5613949229603434, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.65, 'eval_steps_per_second': 20.796, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509025514125824, 'eval_roc_auc': 0.561337037972552, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.714, 'eval_steps_per_second': 20.83, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5613212511576997, 'eval_runtime': 1.3421, 'eval_samples_per_second': 649.739, 'eval_steps_per_second': 20.863, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 41%|████      | 382/931 [09:26<13:19,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 41%|████      | 382/931 [09:26<13:19,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5613475625157869, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.309, 'eval_steps_per_second': 20.817, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5613423002441694, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.238, 'eval_steps_per_second': 20.783, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5613107266144649, 'eval_runtime': 1.3428, 'eval_samples_per_second': 649.405, 'eval_steps_per_second': 20.852, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5612896775279953, 'eval_runtime': 1.3488, 'eval_samples_per_second': 646.491, 'eval_steps_per_second': 20.759, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.5613002020712301, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.039, 'eval_steps_per_second': 20.841, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509025514125824, 'eval_roc_auc': 0.5613054643428476, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.925, 'eval_steps_per_second': 20.837, 'epoch': 0.41}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090256333351135, 'eval_roc_auc': 0.561310726614465, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.637, 'eval_steps_per_second': 20.796, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090256929397583, 'eval_roc_auc': 0.5612791529847605, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.863, 'eval_steps_per_second': 20.835, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090258121490479, 'eval_roc_auc': 0.5612686284415257, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.364, 'eval_steps_per_second': 20.819, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090258717536926, 'eval_roc_auc': 0.5612528416266734, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.078, 'eval_steps_per_second': 20.778, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090259909629822, 'eval_roc_auc': 0.5612423170834386, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.325, 'eval_steps_per_second': 20.818, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090261101722717, 'eval_roc_auc': 0.5612686284415257, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.099, 'eval_steps_per_second': 20.811, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090262293815613, 'eval_roc_auc': 0.5612528416266734, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.619, 'eval_steps_per_second': 20.795, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509026288986206, 'eval_roc_auc': 0.5612686284415256, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.581, 'eval_steps_per_second': 20.794, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090264081954956, 'eval_roc_auc': 0.5613054643428476, 'eval_runtime': 1.3988, 'eval_samples_per_second': 623.414, 'eval_steps_per_second': 20.018, 'epoch': 0.42}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090265274047852, 'eval_roc_auc': 0.5612949397996128, 'eval_runtime': 1.3564, 'eval_samples_per_second': 642.874, 'eval_steps_per_second': 20.643, 'epoch': 0.43}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090266466140747, 'eval_roc_auc': 0.5612844152563778, 'eval_runtime': 1.3584, 'eval_samples_per_second': 641.936, 'eval_steps_per_second': 20.613, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090267062187195, 'eval_roc_auc': 0.561273890713143, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.094, 'eval_steps_per_second': 20.778, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509026825428009, 'eval_roc_auc': 0.5612633661699082, 'eval_runtime': 1.343, 'eval_samples_per_second': 649.292, 'eval_steps_per_second': 20.849, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090268850326538, 'eval_roc_auc': 0.561273890713143, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.914, 'eval_steps_per_second': 20.837, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090270638465881, 'eval_roc_auc': 0.5612317925402037, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.553, 'eval_steps_per_second': 20.825, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090271234512329, 'eval_roc_auc': 0.5612423170834385, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.252, 'eval_steps_per_second': 20.815, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090272426605225, 'eval_roc_auc': 0.5612317925402037, 'eval_runtime': 1.3436, 'eval_samples_per_second': 648.994, 'eval_steps_per_second': 20.839, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090274214744568, 'eval_roc_auc': 0.5612896775279953, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.822, 'eval_steps_per_second': 20.834, 'epoch': 0.43}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090274810791016, 'eval_roc_auc': 0.5612528416266733, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.581, 'eval_steps_per_second': 20.794, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090276598930359, 'eval_roc_auc': 0.5612212679969689, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.108, 'eval_steps_per_second': 20.811, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090278387069702, 'eval_roc_auc': 0.5612370548118212, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.577, 'eval_steps_per_second': 20.826, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090280175209045, 'eval_roc_auc': 0.5613002020712301, 'eval_runtime': 1.3461, 'eval_samples_per_second': 647.795, 'eval_steps_per_second': 20.801, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090281367301941, 'eval_roc_auc': 0.5613212511576997, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.479, 'eval_steps_per_second': 20.791, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090283155441284, 'eval_roc_auc': 0.5613528247874042, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.994, 'eval_steps_per_second': 20.807, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090284943580627, 'eval_roc_auc': 0.561579102466953, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.249, 'eval_steps_per_second': 20.847, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090286731719971, 'eval_roc_auc': 0.5617106592573882, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.068, 'eval_steps_per_second': 20.842, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090288519859314, 'eval_roc_auc': 0.5618001178748843, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.705, 'eval_steps_per_second': 20.798, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.5619106255788497, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.824, 'eval_steps_per_second': 20.834, 'epoch': 0.44}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090292096138, 'eval_roc_auc': 0.561963248295024, 'eval_runtime': 1.3428, 'eval_samples_per_second': 649.412, 'eval_steps_per_second': 20.853, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090293288230896, 'eval_roc_auc': 0.5620211332828156, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.923, 'eval_steps_per_second': 20.837, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090294480323792, 'eval_roc_auc': 0.5621263787151638, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.893, 'eval_steps_per_second': 20.836, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 45%|████▌     | 419/931 [10:20<12:25,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 45%|████▌     | 419/931 [10:20<12:25,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090296864509583, 'eval_roc_auc': 0.5622263618758946, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.899, 'eval_steps_per_second': 20.836, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090298652648926, 'eval_roc_auc': 0.5622447798265555, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.913, 'eval_steps_per_second': 20.837, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090299248695374, 'eval_roc_auc': 0.5622789845920687, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.444, 'eval_steps_per_second': 20.854, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090300440788269, 'eval_roc_auc': 0.5623631809379472, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.788, 'eval_steps_per_second': 20.833, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090302228927612, 'eval_roc_auc': 0.5624368527405911, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.837, 'eval_steps_per_second': 20.834, 'epoch': 0.45}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509030282497406, 'eval_roc_auc': 0.5624526395554433, 'eval_runtime': 1.3662, 'eval_samples_per_second': 638.279, 'eval_steps_per_second': 20.495, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090304613113403, 'eval_roc_auc': 0.5625157868148523, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.582, 'eval_steps_per_second': 20.794, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090305209159851, 'eval_roc_auc': 0.5625315736297045, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.009, 'eval_steps_per_second': 20.776, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090306997299194, 'eval_roc_auc': 0.5625315736297044, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.465, 'eval_steps_per_second': 20.822, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509030818939209, 'eval_roc_auc': 0.5625473604445568, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.496, 'eval_steps_per_second': 20.823, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090310573577881, 'eval_roc_auc': 0.5625999831607309, 'eval_runtime': 5.6858, 'eval_samples_per_second': 153.365, 'eval_steps_per_second': 4.925, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090311765670776, 'eval_roc_auc': 0.562678917234992, 'eval_runtime': 1.3797, 'eval_samples_per_second': 632.03, 'eval_steps_per_second': 20.295, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090312361717224, 'eval_roc_auc': 0.5627578513092532, 'eval_runtime': 1.3672, 'eval_samples_per_second': 637.796, 'eval_steps_per_second': 20.48, 'epoch': 0.46}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090314149856567, 'eval_roc_auc': 0.5627315399511661, 'eval_runtime': 1.3408, 'eval_samples_per_second': 650.34, 'eval_steps_per_second': 20.882, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090315341949463, 'eval_roc_auc': 0.5627657447166794, 'eval_runtime': 1.3425, 'eval_samples_per_second': 649.52, 'eval_steps_per_second': 20.856, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090316534042358, 'eval_roc_auc': 0.5627841626673402, 'eval_runtime': 1.3408, 'eval_samples_per_second': 650.347, 'eval_steps_per_second': 20.883, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090318322181702, 'eval_roc_auc': 0.5627368022227837, 'eval_runtime': 1.3417, 'eval_samples_per_second': 649.934, 'eval_steps_per_second': 20.869, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090320110321045, 'eval_roc_auc': 0.5627789003957229, 'eval_runtime': 1.3417, 'eval_samples_per_second': 649.928, 'eval_steps_per_second': 20.869, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509032130241394, 'eval_roc_auc': 0.562813105161236, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.579, 'eval_steps_per_second': 20.858, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090323090553284, 'eval_roc_auc': 0.5628683590132189, 'eval_runtime': 1.3413, 'eval_samples_per_second': 650.132, 'eval_steps_per_second': 20.876, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090323686599731, 'eval_roc_auc': 0.5629367685442452, 'eval_runtime': 1.3429, 'eval_samples_per_second': 649.337, 'eval_steps_per_second': 20.85, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090324878692627, 'eval_roc_auc': 0.5629630799023322, 'eval_runtime': 1.3419, 'eval_samples_per_second': 649.843, 'eval_steps_per_second': 20.867, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509032666683197, 'eval_roc_auc': 0.562999915803654, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.126, 'eval_steps_per_second': 20.843, 'epoch': 0.47}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090327262878418, 'eval_roc_auc': 0.5629893912604192, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.481, 'eval_steps_per_second': 20.823, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``.`
{'eval_loss': 0.5090328454971313, 'eval_roc_auc': 0.5630525385198282, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.949, 'eval_steps_per_second': 20.806, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090330839157104, 'eval_roc_auc': 0.5631314725940895, 'eval_runtime': 1.342, 'eval_samples_per_second': 649.782, 'eval_steps_per_second': 20.865, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090330839157104, 'eval_roc_auc': 0.5631998821251157, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.104, 'eval_steps_per_second': 20.779, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509033203125, 'eval_roc_auc': 0.5632367180264376, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.626, 'eval_steps_per_second': 20.763, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090332627296448, 'eval_roc_auc': 0.5632682916561421, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.55, 'eval_steps_per_second': 20.825, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090333819389343, 'eval_roc_auc': 0.5632682916561422, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.044, 'eval_steps_per_second': 20.841, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 48%|████▊     | 451/931 [11:12<11:39,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 48%|████▊     | 451/931 [11:12<11:39,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090334415435791, 'eval_roc_auc': 0.5632946030142292, 'eval_runtime': 1.3691, 'eval_samples_per_second': 636.905, 'eval_steps_per_second': 20.451, 'epoch': 0.48}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090335607528687, 'eval_roc_auc': 0.563305127557464, 'eval_runtime': 1.366, 'eval_samples_per_second': 638.358, 'eval_steps_per_second': 20.498, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090336203575134, 'eval_roc_auc': 0.5640523701271365, 'eval_runtime': 1.3434, 'eval_samples_per_second': 649.078, 'eval_steps_per_second': 20.842, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090336799621582, 'eval_roc_auc': 0.5646364822766692, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.023, 'eval_steps_per_second': 20.808, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090336799621582, 'eval_roc_auc': 0.5652363812410541, 'eval_runtime': 1.3563, 'eval_samples_per_second': 642.933, 'eval_steps_per_second': 20.645, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509033739566803, 'eval_roc_auc': 0.5659046897364655, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.983, 'eval_steps_per_second': 20.807, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.5664388103056327, 'eval_runtime': 1.3536, 'eval_samples_per_second': 644.204, 'eval_steps_per_second': 20.685, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.5670097667761219, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.036, 'eval_steps_per_second': 20.776, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090339183807373, 'eval_roc_auc': 0.5672570935421403, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.45, 'eval_steps_per_second': 20.79, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090339779853821, 'eval_roc_auc': 0.5674860023574977, 'eval_runtime': 1.343, 'eval_samples_per_second': 649.296, 'eval_steps_per_second': 20.849, 'epoch': 0.49}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090340375900269, 'eval_roc_auc': 0.5678885661362296, 'eval_runtime': 1.3495, 'eval_samples_per_second': 646.147, 'eval_steps_per_second': 20.748, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090340971946716, 'eval_roc_auc': 0.5681043192725435, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.028, 'eval_steps_per_second': 20.776, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 50%|████▉     | 464/931 [11:30<11:21,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 50%|████▉     | 464/931 [11:30<11:21,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090340971946716, 'eval_roc_auc': 0.5683990064831186, 'eval_runtime': 1.3507, 'eval_samples_per_second': 645.568, 'eval_steps_per_second': 20.729, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090341567993164, 'eval_roc_auc': 0.5686437021133284, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.954, 'eval_steps_per_second': 20.774, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.509034276008606, 'eval_roc_auc': 0.568825250484129, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.568, 'eval_steps_per_second': 20.826, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343356132507, 'eval_roc_auc': 0.5689541761387557, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.661, 'eval_steps_per_second': 20.764, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343356132507, 'eval_roc_auc': 0.5691620358676434, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.143, 'eval_steps_per_second': 20.812, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090343952178955, 'eval_roc_auc': 0.5693251662877832, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.449, 'eval_steps_per_second': 20.822, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090344548225403, 'eval_roc_auc': 0.5694777721646881, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.77, 'eval_steps_per_second': 20.832, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090345144271851, 'eval_roc_auc': 0.5696066978193146, 'eval_runtime': 1.3436, 'eval_samples_per_second': 648.997, 'eval_steps_per_second': 20.839, 'epoch': 0.5}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090345740318298, 'eval_roc_auc': 0.5696724762145323, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.772, 'eval_steps_per_second': 20.832, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090346336364746, 'eval_roc_auc': 0.5697671971036458, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.639, 'eval_steps_per_second': 20.764, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.5697935084617327, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.887, 'eval_steps_per_second': 20.836, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090347528457642, 'eval_roc_auc': 0.5698303443630547, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.721, 'eval_steps_per_second': 20.83, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090348124504089, 'eval_roc_auc': 0.5698829670792287, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.64, 'eval_steps_per_second': 20.828, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090348124504089, 'eval_roc_auc': 0.5699119095731244, 'eval_runtime': 1.4029, 'eval_samples_per_second': 621.569, 'eval_steps_per_second': 19.959, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.5700039993264292, 'eval_runtime': 1.3555, 'eval_samples_per_second': 643.303, 'eval_steps_per_second': 20.657, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090349912643433, 'eval_roc_auc': 0.5700829334006905, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.935, 'eval_steps_per_second': 20.837, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509035050868988, 'eval_roc_auc': 0.5701197693020124, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.147, 'eval_steps_per_second': 20.78, 'epoch': 0.51}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351104736328, 'eval_roc_auc': 0.5701881788330386, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.924, 'eval_steps_per_second': 20.805, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351104736328, 'eval_roc_auc': 0.5701566052033342, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.747, 'eval_steps_per_second': 20.831, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090352296829224, 'eval_roc_auc': 0.5702513260924476, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.144, 'eval_steps_per_second': 20.78, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090352296829224, 'eval_roc_auc': 0.5703039488086217, 'eval_runtime': 1.3489, 'eval_samples_per_second': 646.456, 'eval_steps_per_second': 20.758, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090353488922119, 'eval_roc_auc': 0.5703407847099435, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.208, 'eval_steps_per_second': 20.782, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090353488922119, 'eval_roc_auc': 0.5703670960680307, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.047, 'eval_steps_per_second': 20.809, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090354084968567, 'eval_roc_auc': 0.5704223499200135, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.93, 'eval_steps_per_second': 20.805, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090354681015015, 'eval_roc_auc': 0.570461816957144, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.365, 'eval_steps_per_second': 20.787, 'epoch': 0.52}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090354681015015, 'eval_roc_auc': 0.5704986528584659, 'eval_runtime': 1.3514, 'eval_samples_per_second': 645.246, 'eval_steps_per_second': 20.719, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090355277061462, 'eval_roc_auc': 0.5705197019449356, 'eval_runtime': 1.3494, 'eval_samples_per_second': 646.206, 'eval_steps_per_second': 20.75, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090356469154358, 'eval_roc_auc': 0.570524964216553, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.963, 'eval_steps_per_second': 20.774, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 53%|█████▎    | 493/931 [12:12<10:39,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 53%|█████▎    | 493/931 [12:12<10:39,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090356469154358, 'eval_roc_auc': 0.5705407510314052, 'eval_runtime': 1.3488, 'eval_samples_per_second': 646.483, 'eval_steps_per_second': 20.759, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.5705723246611099, 'eval_runtime': 1.3503, 'eval_samples_per_second': 645.771, 'eval_steps_per_second': 20.736, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.570588111475962, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.809, 'eval_steps_per_second': 20.769, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090357661247253, 'eval_roc_auc': 0.5705828492043445, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.025, 'eval_steps_per_second': 20.776, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090358257293701, 'eval_roc_auc': 0.57055127557464, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.44, 'eval_steps_per_second': 20.789, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090358853340149, 'eval_roc_auc': 0.5705460133030227, 'eval_runtime': 1.3503, 'eval_samples_per_second': 645.769, 'eval_steps_per_second': 20.736, 'epoch': 0.53}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090359449386597, 'eval_roc_auc': 0.5705565378462575, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.867, 'eval_steps_per_second': 20.771, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'loss': 0.0001, 'learning_rate': 0.0005, 'epoch': 0.54}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090360045433044, 'eval_roc_auc': 0.5705723246611097, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.231, 'eval_steps_per_second': 20.783, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090360641479492, 'eval_roc_auc': 0.5705670623894923, 'eval_runtime': 1.3496, 'eval_samples_per_second': 646.127, 'eval_steps_per_second': 20.747, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509036123752594, 'eval_roc_auc': 0.5705723246611096, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.242, 'eval_steps_per_second': 20.783, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509036123752594, 'eval_roc_auc': 0.5705723246611097, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.619, 'eval_steps_per_second': 20.763, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090361833572388, 'eval_roc_auc': 0.5705828492043445, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.917, 'eval_steps_per_second': 20.773, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090363025665283, 'eval_roc_auc': 0.5707196682663973, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.057, 'eval_steps_per_second': 20.777, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090363621711731, 'eval_roc_auc': 0.5707880777974237, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.415, 'eval_steps_per_second': 20.789, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364217758179, 'eval_roc_auc': 0.5708143891555106, 'eval_runtime': 1.351, 'eval_samples_per_second': 645.426, 'eval_steps_per_second': 20.725, 'epoch': 0.54}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364813804626, 'eval_roc_auc': 0.5710932895512335, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.232, 'eval_steps_per_second': 20.815, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090364813804626, 'eval_roc_auc': 0.5712827313294603, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.237, 'eval_steps_per_second': 20.815, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090365409851074, 'eval_roc_auc': 0.5715037467373916, 'eval_runtime': 1.3423, 'eval_samples_per_second': 649.613, 'eval_steps_per_second': 20.859, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509036660194397, 'eval_roc_auc': 0.5717142376020881, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.888, 'eval_steps_per_second': 20.772, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090367197990417, 'eval_roc_auc': 0.5719194661951671, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.793, 'eval_steps_per_second': 20.769, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090367197990417, 'eval_roc_auc': 0.5720668098004547, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.757, 'eval_steps_per_second': 20.832, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367794036865, 'eval_roc_auc': 0.5722457270354467, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.668, 'eval_steps_per_second': 20.829, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 55%|█████▌    | 515/931 [12:46<10:05,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 55%|█████▌    | 515/931 [12:46<10:05,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367794036865, 'eval_roc_auc': 0.5723614970110298, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.927, 'eval_steps_per_second': 20.773, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090363025665283, 'eval_roc_auc': 0.5771870000841963, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.258, 'eval_steps_per_second': 20.816, 'epoch': 0.55}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.5814599646375347, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.864, 'eval_steps_per_second': 20.835, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.585822387808369, 'eval_runtime': 1.3482, 'eval_samples_per_second': 646.784, 'eval_steps_per_second': 20.768, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.5902111223372906, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.611, 'eval_steps_per_second': 20.763, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090340971946716, 'eval_roc_auc': 0.5938341963458786, 'eval_runtime': 1.3485, 'eval_samples_per_second': 646.657, 'eval_steps_per_second': 20.764, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090336203575134, 'eval_roc_auc': 0.5973783362802054, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.595, 'eval_steps_per_second': 20.762, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090331435203552, 'eval_roc_auc': 0.6001199797928769, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.426, 'eval_steps_per_second': 20.789, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090322494506836, 'eval_roc_auc': 0.6047770901742865, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.678, 'eval_steps_per_second': 20.797, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090318322181702, 'eval_roc_auc': 0.6067767533889029, 'eval_runtime': 1.3517, 'eval_samples_per_second': 645.09, 'eval_steps_per_second': 20.714, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.509031355381012, 'eval_roc_auc': 0.6083817462322135, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.617, 'eval_steps_per_second': 20.795, 'epoch': 0.56}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090311169624329, 'eval_roc_auc': 0.6097709859392103, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.34, 'eval_steps_per_second': 20.818, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090307593345642, 'eval_roc_auc': 0.6111023406584155, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.71, 'eval_steps_per_second': 20.798, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090305209159851, 'eval_roc_auc': 0.6124705312789426, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.025, 'eval_steps_per_second': 20.808, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.509030282497406, 'eval_roc_auc': 0.6131388397743538, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.906, 'eval_steps_per_second': 20.836, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090300440788269, 'eval_roc_auc': 0.6143596867895933, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.364, 'eval_steps_per_second': 20.819, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090298652648926, 'eval_roc_auc': 0.6151121916308833, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.359, 'eval_steps_per_second': 20.787, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090296268463135, 'eval_roc_auc': 0.6157778689904858, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.596, 'eval_steps_per_second': 20.794, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090295076370239, 'eval_roc_auc': 0.6161014986949567, 'eval_runtime': 1.3457, 'eval_samples_per_second': 648.01, 'eval_steps_per_second': 20.808, 'epoch': 0.57}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090293288230896, 'eval_roc_auc': 0.6164909067946451, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.586, 'eval_steps_per_second': 20.826, 'epoch': 0.57}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090292692184448, 'eval_roc_auc': 0.6167619137829418, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.404, 'eval_steps_per_second': 20.82, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090292096138, 'eval_roc_auc': 0.6172434116359349, 'eval_runtime': 1.3431, 'eval_samples_per_second': 649.242, 'eval_steps_per_second': 20.847, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090291500091553, 'eval_roc_auc': 0.6174644270438663, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.084, 'eval_steps_per_second': 20.81, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.617772269933485, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.769, 'eval_steps_per_second': 20.8, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.6178801465016419, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.498, 'eval_steps_per_second': 20.823, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.6181800959838343, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.381, 'eval_steps_per_second': 20.82, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.6184589963795571, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.233, 'eval_steps_per_second': 20.783, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.6184642586511746, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.871, 'eval_steps_per_second': 20.835, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 59%|█████▊    | 545/931 [13:28<09:21,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 59%|█████▊    | 545/931 [13:28<09:21,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090291500091553, 'eval_roc_auc': 0.6185695040835226, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.01, 'eval_steps_per_second': 20.84, 'epoch': 0.58}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090292096138, 'eval_roc_auc': 0.6187326345036626, 'eval_runtime': 1.3639, 'eval_samples_per_second': 639.332, 'eval_steps_per_second': 20.529, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090292692184448, 'eval_roc_auc': 0.6188589290224804, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.114, 'eval_steps_per_second': 20.811, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090293288230896, 'eval_roc_auc': 0.6190378462574724, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.915, 'eval_steps_per_second': 20.837, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090293288230896, 'eval_roc_auc': 0.6190010103561505, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.571, 'eval_steps_per_second': 20.794, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090294480323792, 'eval_roc_auc': 0.6191167803317335, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.126, 'eval_steps_per_second': 20.811, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090295076370239, 'eval_roc_auc': 0.6191430916898206, 'eval_runtime': 1.3473, 'eval_samples_per_second': 647.244, 'eval_steps_per_second': 20.783, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090295672416687, 'eval_roc_auc': 0.6191430916898206, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.115, 'eval_steps_per_second': 20.811, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090296268463135, 'eval_roc_auc': 0.6191615096404817, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.035, 'eval_steps_per_second': 20.841, 'epoch': 0.59}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509029746055603, 'eval_roc_auc': 0.6192904352951082, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.571, 'eval_steps_per_second': 20.794, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090298652648926, 'eval_roc_auc': 0.6192956975667256, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.623, 'eval_steps_per_second': 20.827, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090299248695374, 'eval_roc_auc': 0.6193351646038563, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.773, 'eval_steps_per_second': 20.832, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090299844741821, 'eval_roc_auc': 0.6193693693693694, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.478, 'eval_steps_per_second': 20.791, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090300440788269, 'eval_roc_auc': 0.6193956807274564, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.161, 'eval_steps_per_second': 20.845, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090302228927612, 'eval_roc_auc': 0.6194035741348825, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.989, 'eval_steps_per_second': 20.807, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509030282497406, 'eval_roc_auc': 0.6194377789003958, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.05, 'eval_steps_per_second': 20.809, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090303421020508, 'eval_roc_auc': 0.6194325166287783, 'eval_runtime': 1.3507, 'eval_samples_per_second': 645.606, 'eval_steps_per_second': 20.73, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090304613113403, 'eval_roc_auc': 0.6194588279868654, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.669, 'eval_steps_per_second': 20.829, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090305209159851, 'eval_roc_auc': 0.6194377789003958, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.764, 'eval_steps_per_second': 20.832, 'epoch': 0.6}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090306997299194, 'eval_roc_auc': 0.619416729813926, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.567, 'eval_steps_per_second': 20.826, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509030818939209, 'eval_roc_auc': 0.6194009429990739, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.247, 'eval_steps_per_second': 20.815, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090309381484985, 'eval_roc_auc': 0.6193851561842216, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.922, 'eval_steps_per_second': 20.837, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090310573577881, 'eval_roc_auc': 0.6193825250484128, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.34, 'eval_steps_per_second': 20.818, 'epoch': 0.61}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090311169624329, 'eval_roc_auc': 0.6194219920855435, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.704, 'eval_steps_per_second': 20.798, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090311765670776, 'eval_roc_auc': 0.6194325166287783, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.177, 'eval_steps_per_second': 20.845, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090312957763672, 'eval_roc_auc': 0.6194719836659088, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.397, 'eval_steps_per_second': 20.82, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090314149856567, 'eval_roc_auc': 0.6194246232213522, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.839, 'eval_steps_per_second': 20.802, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090315341949463, 'eval_roc_auc': 0.6194272543571608, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.089, 'eval_steps_per_second': 20.81, 'epoch': 0.61}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090316534042358, 'eval_roc_auc': 0.6193956807274563, 'eval_runtime': 1.3507, 'eval_samples_per_second': 645.584, 'eval_steps_per_second': 20.73, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090317130088806, 'eval_roc_auc': 0.6193851561842216, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.317, 'eval_steps_per_second': 20.818, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090318322181702, 'eval_roc_auc': 0.6193851561842216, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.022, 'eval_steps_per_second': 20.808, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090319514274597, 'eval_roc_auc': 0.6193693693693694, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.492, 'eval_steps_per_second': 20.823, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090319514274597, 'eval_roc_auc': 0.6192693862086386, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.42, 'eval_steps_per_second': 20.821, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090320706367493, 'eval_roc_auc': 0.6192851730234907, 'eval_runtime': 10.7052, 'eval_samples_per_second': 81.456, 'eval_steps_per_second': 2.616, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509032130241394, 'eval_roc_auc': 0.6193483202828998, 'eval_runtime': 1.3346, 'eval_samples_per_second': 653.378, 'eval_steps_per_second': 20.98, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090323090553284, 'eval_roc_auc': 0.6193167466531952, 'eval_runtime': 1.3337, 'eval_samples_per_second': 653.827, 'eval_steps_per_second': 20.994, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090323686599731, 'eval_roc_auc': 0.6192956975667255, 'eval_runtime': 1.3361, 'eval_samples_per_second': 652.665, 'eval_steps_per_second': 20.957, 'epoch': 0.62}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090324282646179, 'eval_roc_auc': 0.6192983287025343, 'eval_runtime': 1.337, 'eval_samples_per_second': 652.216, 'eval_steps_per_second': 20.943, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090324878692627, 'eval_roc_auc': 0.6193220089248126, 'eval_runtime': 1.3383, 'eval_samples_per_second': 651.592, 'eval_steps_per_second': 20.923, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509032666683197, 'eval_roc_auc': 0.6192693862086386, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.212, 'eval_steps_per_second': 20.814, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090327262878418, 'eval_roc_auc': 0.6192641239370211, 'eval_runtime': 1.3419, 'eval_samples_per_second': 649.845, 'eval_steps_per_second': 20.867, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090327858924866, 'eval_roc_auc': 0.6192220257640818, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.192, 'eval_steps_per_second': 20.846, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090328454971313, 'eval_roc_auc': 0.6192062389492297, 'eval_runtime': 1.342, 'eval_samples_per_second': 649.775, 'eval_steps_per_second': 20.864, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090329647064209, 'eval_roc_auc': 0.6192193946282731, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.12, 'eval_steps_per_second': 20.811, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090330243110657, 'eval_roc_auc': 0.619211501220847, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.537, 'eval_steps_per_second': 20.792, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090330839157104, 'eval_roc_auc': 0.6192220257640819, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.635, 'eval_steps_per_second': 20.828, 'epoch': 0.63}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090331435203552, 'eval_roc_auc': 0.6191957144059947, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.455, 'eval_steps_per_second': 20.854, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090332627296448, 'eval_roc_auc': 0.6192009766776122, 'eval_runtime': 1.3417, 'eval_samples_per_second': 649.923, 'eval_steps_per_second': 20.869, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 64%|██████▍   | 594/931 [14:50<08:14,  1.47s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 64%|██████▍   | 594/931 [14:50<08:14,  1.47s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090333223342896, 'eval_roc_auc': 0.6191825587269513, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.132, 'eval_steps_per_second': 20.844, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090333819389343, 'eval_roc_auc': 0.6191378294182033, 'eval_runtime': 1.3413, 'eval_samples_per_second': 650.097, 'eval_steps_per_second': 20.875, 'epoch': 0.64}
 64%|██████▍   | 594/931 [14:50<08:14,  1.47s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090334415435791, 'eval_roc_auc': 0.6191457228256294, 'eval_runtime': 1.3426, 'eval_samples_per_second': 649.489, 'eval_steps_per_second': 20.855, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090335607528687, 'eval_roc_auc': 0.6191904521343773, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.947, 'eval_steps_per_second': 20.838, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090335607528687, 'eval_roc_auc': 0.6191325671465858, 'eval_runtime': 1.3419, 'eval_samples_per_second': 649.818, 'eval_steps_per_second': 20.866, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090336799621582, 'eval_roc_auc': 0.6191273048749685, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.662, 'eval_steps_per_second': 20.829, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509033739566803, 'eval_roc_auc': 0.6191220426033509, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.157, 'eval_steps_per_second': 20.812, 'epoch': 0.64}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.619085206702029, 'eval_runtime': 1.3578, 'eval_samples_per_second': 642.212, 'eval_steps_per_second': 20.621, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090338587760925, 'eval_roc_auc': 0.6191325671465859, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.017, 'eval_steps_per_second': 20.808, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090339183807373, 'eval_roc_auc': 0.6190378462574725, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.792, 'eval_steps_per_second': 20.833, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090339779853821, 'eval_roc_auc': 0.6189852235412983, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.07, 'eval_steps_per_second': 20.842, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090340971946716, 'eval_roc_auc': 0.6190115348993854, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.871, 'eval_steps_per_second': 20.835, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509034276008606, 'eval_roc_auc': 0.6190273217142377, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.434, 'eval_steps_per_second': 20.821, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343356132507, 'eval_roc_auc': 0.6189904858129157, 'eval_runtime': 1.3457, 'eval_samples_per_second': 648.014, 'eval_steps_per_second': 20.808, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343952178955, 'eval_roc_auc': 0.6189536499115939, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.404, 'eval_steps_per_second': 20.82, 'epoch': 0.65}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090344548225403, 'eval_roc_auc': 0.6189404942325503, 'eval_runtime': 1.3479, 'eval_samples_per_second': 646.953, 'eval_steps_per_second': 20.774, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090345144271851, 'eval_roc_auc': 0.6188931337879937, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.755, 'eval_steps_per_second': 20.832, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090345740318298, 'eval_roc_auc': 0.6188747158373327, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.966, 'eval_steps_per_second': 20.774, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 66%|██████▌   | 614/931 [15:18<07:41,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 66%|██████▌   | 614/931 [15:18<07:41,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.6188220931211585, 'eval_runtime': 1.3481, 'eval_samples_per_second': 646.824, 'eval_steps_per_second': 20.77, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090347528457642, 'eval_roc_auc': 0.6188431422076281, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.298, 'eval_steps_per_second': 20.817, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090348124504089, 'eval_roc_auc': 0.6188484044792455, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.285, 'eval_steps_per_second': 20.816, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.6188641912940979, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.088, 'eval_steps_per_second': 20.81, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.6188484044792456, 'eval_runtime': 1.3511, 'eval_samples_per_second': 645.389, 'eval_steps_per_second': 20.724, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090349316596985, 'eval_roc_auc': 0.6188326176643933, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.325, 'eval_steps_per_second': 20.818, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509035050868988, 'eval_roc_auc': 0.6188220931211585, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.874, 'eval_steps_per_second': 20.835, 'epoch': 0.66}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090351104736328, 'eval_roc_auc': 0.6188063063063063, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.446, 'eval_steps_per_second': 20.822, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.6187852572198367, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.634, 'eval_steps_per_second': 20.828, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.6187957817630715, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.109, 'eval_steps_per_second': 20.779, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090352296829224, 'eval_roc_auc': 0.6187536835901322, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.214, 'eval_steps_per_second': 20.814, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090352892875671, 'eval_roc_auc': 0.6187905194914541, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.162, 'eval_steps_per_second': 20.813, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090352892875671, 'eval_roc_auc': 0.6187536835901322, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.861, 'eval_steps_per_second': 20.835, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090353488922119, 'eval_roc_auc': 0.618756314725941, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.97, 'eval_steps_per_second': 20.774, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090354681015015, 'eval_roc_auc': 0.6187957817630715, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.908, 'eval_steps_per_second': 20.836, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090355277061462, 'eval_roc_auc': 0.6187589458617497, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.979, 'eval_steps_per_second': 20.807, 'epoch': 0.67}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509035587310791, 'eval_roc_auc': 0.6187484213185147, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.44, 'eval_steps_per_second': 20.821, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509035587310791, 'eval_roc_auc': 0.61873789677528, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.681, 'eval_steps_per_second': 20.797, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 68%|██████▊   | 631/931 [15:44<07:16,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 68%|██████▊   | 631/931 [15:44<07:16,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509035587310791, 'eval_roc_auc': 0.6187115854171928, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.421, 'eval_steps_per_second': 20.821, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090356469154358, 'eval_roc_auc': 0.6187168476888103, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.055, 'eval_steps_per_second': 20.777, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.6186589627010188, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.33, 'eval_steps_per_second': 20.818, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090357661247253, 'eval_roc_auc': 0.6186537004294013, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.568, 'eval_steps_per_second': 20.793, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090358257293701, 'eval_roc_auc': 0.6186063399848446, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.399, 'eval_steps_per_second': 20.82, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090358853340149, 'eval_roc_auc': 0.6186010777132273, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.712, 'eval_steps_per_second': 20.798, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090359449386597, 'eval_roc_auc': 0.6186431758861666, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.881, 'eval_steps_per_second': 20.804, 'epoch': 0.68}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090360045433044, 'eval_roc_auc': 0.6186326513429317, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.573, 'eval_steps_per_second': 20.794, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090360045433044, 'eval_roc_auc': 0.6186405447503578, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.315, 'eval_steps_per_second': 20.817, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090360641479492, 'eval_roc_auc': 0.6186063399848446, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.918, 'eval_steps_per_second': 20.805, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090360641479492, 'eval_roc_auc': 0.6185852908983751, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.998, 'eval_steps_per_second': 20.807, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.509036123752594, 'eval_roc_auc': 0.618585290898375, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.335, 'eval_steps_per_second': 20.818, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090361833572388, 'eval_roc_auc': 0.6186063399848447, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.632, 'eval_steps_per_second': 20.796, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090362429618835, 'eval_roc_auc': 0.6185721352193315, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.9, 'eval_steps_per_second': 20.804, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090363025665283, 'eval_roc_auc': 0.6185800286267576, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.677, 'eval_steps_per_second': 20.797, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090363621711731, 'eval_roc_auc': 0.6185800286267575, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.131, 'eval_steps_per_second': 20.779, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090364217758179, 'eval_roc_auc': 0.6185431927254357, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.086, 'eval_steps_per_second': 20.778, 'epoch': 0.69}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364217758179, 'eval_roc_auc': 0.6185168813673486, 'eval_runtime': 1.3494, 'eval_samples_per_second': 646.228, 'eval_steps_per_second': 20.75, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 70%|██████▉   | 649/931 [16:10<06:51,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 70%|██████▉   | 649/931 [16:10<06:51,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090364813804626, 'eval_roc_auc': 0.6184958322808789, 'eval_runtime': 1.3457, 'eval_samples_per_second': 648.001, 'eval_steps_per_second': 20.807, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090365409851074, 'eval_roc_auc': 0.6185063568241138, 'eval_runtime': 1.3529, 'eval_samples_per_second': 644.521, 'eval_steps_per_second': 20.696, 'epoch': 0.7}
 70%|██████▉   | 649/931 [16:10<06:51,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090366005897522, 'eval_roc_auc': 0.618406373663383, 'eval_runtime': 1.35, 'eval_samples_per_second': 645.918, 'eval_steps_per_second': 20.74, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509036660194397, 'eval_roc_auc': 0.6183958491201482, 'eval_runtime': 1.3496, 'eval_samples_per_second': 646.098, 'eval_steps_per_second': 20.746, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509036660194397, 'eval_roc_auc': 0.6183853245769133, 'eval_runtime': 1.379, 'eval_samples_per_second': 632.336, 'eval_steps_per_second': 20.304, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090367197990417, 'eval_roc_auc': 0.6183432264039741, 'eval_runtime': 1.3518, 'eval_samples_per_second': 645.088, 'eval_steps_per_second': 20.714, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367197990417, 'eval_roc_auc': 0.6183221773175044, 'eval_runtime': 1.3514, 'eval_samples_per_second': 645.264, 'eval_steps_per_second': 20.72, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367794036865, 'eval_roc_auc': 0.6183379641323566, 'eval_runtime': 1.3541, 'eval_samples_per_second': 643.979, 'eval_steps_per_second': 20.678, 'epoch': 0.7}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090368390083313, 'eval_roc_auc': 0.6183379641323566, 'eval_runtime': 1.3529, 'eval_samples_per_second': 644.52, 'eval_steps_per_second': 20.696, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090368390083313, 'eval_roc_auc': 0.6183169150458869, 'eval_runtime': 1.3535, 'eval_samples_per_second': 644.26, 'eval_steps_per_second': 20.687, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090368986129761, 'eval_roc_auc': 0.6182642923297128, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.88, 'eval_steps_per_second': 20.771, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 71%|███████   | 660/931 [16:26<06:36,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 71%|███████   | 660/931 [16:26<06:36,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090368986129761, 'eval_roc_auc': 0.6182958659594173, 'eval_runtime': 1.3577, 'eval_samples_per_second': 642.255, 'eval_steps_per_second': 20.623, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 71%|███████   | 662/931 [16:28<06:34,  1.47s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 71%|███████   | 662/931 [16:28<06:34,  1.47s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090369582176208, 'eval_roc_auc': 0.6182642923297129, 'eval_runtime': 1.3606, 'eval_samples_per_second': 640.911, 'eval_steps_per_second': 20.58, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090370178222656, 'eval_roc_auc': 0.6182037762061126, 'eval_runtime': 1.3484, 'eval_samples_per_second': 646.673, 'eval_steps_per_second': 20.765, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090370774269104, 'eval_roc_auc': 0.6182169318851561, 'eval_runtime': 1.3552, 'eval_samples_per_second': 643.464, 'eval_steps_per_second': 20.662, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090370774269104, 'eval_roc_auc': 0.6182327187000084, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.89, 'eval_steps_per_second': 20.772, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.6182064073419213, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.305, 'eval_steps_per_second': 20.817, 'epoch': 0.71}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s.`
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.6182432432432432, 'eval_runtime': 1.3476, 'eval_samples_per_second': 647.083, 'eval_steps_per_second': 20.778, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.`s.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.`s.`
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.6181853582554517, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.372, 'eval_steps_per_second': 20.819, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.`s.`
{'eval_loss': 0.5090372562408447, 'eval_roc_auc': 0.6181800959838343, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.99, 'eval_steps_per_second': 20.807, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090372562408447, 'eval_roc_auc': 0.6181695714405995, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.416, 'eval_steps_per_second': 20.821, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.`s.`
{'eval_loss': 0.5090373158454895, 'eval_roc_auc': 0.618201145070304, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.798, 'eval_steps_per_second': 20.833, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.`s.`
{'eval_loss': 0.5090373158454895, 'eval_roc_auc': 0.6181485223541299, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.881, 'eval_steps_per_second': 20.836, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.`s.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.`s.`
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.6181906205270692, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.453, 'eval_steps_per_second': 20.79, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.6181748337122169, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.959, 'eval_steps_per_second': 20.806, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.6182090384777301, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.242, 'eval_steps_per_second': 20.815, 'epoch': 0.72}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.6182169318851561, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.303, 'eval_steps_per_second': 20.817, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.6182248252925823, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.357, 'eval_steps_per_second': 20.819, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.6182485055148607, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.937, 'eval_steps_per_second': 20.837, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090375542640686, 'eval_roc_auc': 0.6182064073419213, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.21, 'eval_steps_per_second': 20.814, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 73%|███████▎  | 679/931 [16:54<06:06,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 73%|███████▎  | 679/931 [16:54<06:06,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090376138687134, 'eval_roc_auc': 0.6181748337122169, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.887, 'eval_steps_per_second': 20.836, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.6181537846257472, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.322, 'eval_steps_per_second': 20.818, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 73%|███████▎  | 679/931 [16:54<06:06,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.6181537846257472, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.215, 'eval_steps_per_second': 20.814, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.6181169487244254, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.424, 'eval_steps_per_second': 20.821, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.6181327355392776, 'eval_runtime': 1.3429, 'eval_samples_per_second': 649.329, 'eval_steps_per_second': 20.85, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090369582176208, 'eval_roc_auc': 0.6205481182116697, 'eval_runtime': 1.3602, 'eval_samples_per_second': 641.09, 'eval_steps_per_second': 20.585, 'epoch': 0.73}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090360641479492, 'eval_roc_auc': 0.6217005556958828, 'eval_runtime': 1.3469, 'eval_samples_per_second': 647.402, 'eval_steps_per_second': 20.788, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.6227845836490696, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.771, 'eval_steps_per_second': 20.8, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090343356132507, 'eval_roc_auc': 0.6228108950071566, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.738, 'eval_steps_per_second': 20.799, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090335011482239, 'eval_roc_auc': 0.622771427970026, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.769, 'eval_steps_per_second': 20.832, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509032666683197, 'eval_roc_auc': 0.6224530605371726, 'eval_runtime': 1.3516, 'eval_samples_per_second': 645.183, 'eval_steps_per_second': 20.717, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 74%|███████▍  | 691/931 [17:10<05:49,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 74%|███████▍  | 691/931 [17:10<05:49,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090319514274597, 'eval_roc_auc': 0.6220847015239539, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.195, 'eval_steps_per_second': 20.846, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090311765670776, 'eval_roc_auc': 0.6213637703123684, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.222, 'eval_steps_per_second': 20.814, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 74%|███████▍  | 691/931 [17:10<05:49,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 74%|███████▍  | 691/931 [17:10<05:49,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090304613113403, 'eval_roc_auc': 0.6207743958912183, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.5, 'eval_steps_per_second': 20.823, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509029746055603, 'eval_roc_auc': 0.6201666035194072, 'eval_runtime': 1.3563, 'eval_samples_per_second': 642.908, 'eval_steps_per_second': 20.644, 'epoch': 0.74}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090291500091553, 'eval_roc_auc': 0.6192746484802559, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.364, 'eval_steps_per_second': 20.787, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090285539627075, 'eval_roc_auc': 0.6185116190957313, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.324, 'eval_steps_per_second': 20.818, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090280175209045, 'eval_roc_auc': 0.6178275237854678, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.206, 'eval_steps_per_second': 20.814, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090275406837463, 'eval_roc_auc': 0.6171802643765261, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.022, 'eval_steps_per_second': 20.84, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090270638465881, 'eval_roc_auc': 0.6167329712890459, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.75, 'eval_steps_per_second': 20.831, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090266466140747, 'eval_roc_auc': 0.6162330554853919, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.593, 'eval_steps_per_second': 20.826, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090263485908508, 'eval_roc_auc': 0.6158015492127642, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.492, 'eval_steps_per_second': 20.791, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509026050567627, 'eval_roc_auc': 0.615275322051023, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.79, 'eval_steps_per_second': 20.833, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090257525444031, 'eval_roc_auc': 0.615096404816031, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.253, 'eval_steps_per_second': 20.815, 'epoch': 0.75}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509025514125824, 'eval_roc_auc': 0.6146385871853162, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.351, 'eval_steps_per_second': 20.819, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090252757072449, 'eval_roc_auc': 0.6142386545423928, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.134, 'eval_steps_per_second': 20.812, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090251564979553, 'eval_roc_auc': 0.6141018354803401, 'eval_runtime': 1.3457, 'eval_samples_per_second': 647.999, 'eval_steps_per_second': 20.807, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090250372886658, 'eval_roc_auc': 0.6138755578007914, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.941, 'eval_steps_per_second': 20.838, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090249180793762, 'eval_roc_auc': 0.6137071651090342, 'eval_runtime': 1.3441, 'eval_samples_per_second': 648.754, 'eval_steps_per_second': 20.832, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 76%|███████▌  | 709/931 [17:36<05:22,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 76%|███████▌  | 709/931 [17:36<05:22,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090248584747314, 'eval_roc_auc': 0.6135703460469815, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.793, 'eval_steps_per_second': 20.833, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.6134072156268418, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.869, 'eval_steps_per_second': 20.803, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.6131756756756757, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.062, 'eval_steps_per_second': 20.841, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.612967815946788, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.526, 'eval_steps_per_second': 20.824, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.6128967752799529, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.517, 'eval_steps_per_second': 20.824, 'epoch': 0.76}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.6127862675759872, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.454, 'eval_steps_per_second': 20.822, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090247988700867, 'eval_roc_auc': 0.6127310137240043, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.458, 'eval_steps_per_second': 20.822, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090248584747314, 'eval_roc_auc': 0.6126020880693778, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.682, 'eval_steps_per_second': 20.829, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 77%|███████▋  | 716/931 [17:48<05:12,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 77%|███████▋  | 716/931 [17:48<05:12,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090249180793762, 'eval_roc_auc': 0.6125231539951166, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.491, 'eval_steps_per_second': 20.823, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090250372886658, 'eval_roc_auc': 0.6125126294518818, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.747, 'eval_steps_per_second': 20.799, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090250968933105, 'eval_roc_auc': 0.6124757935505599, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.847, 'eval_steps_per_second': 20.802, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090251564979553, 'eval_roc_auc': 0.6124600067357077, 'eval_runtime': 1.3436, 'eval_samples_per_second': 649.026, 'eval_steps_per_second': 20.84, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090252757072449, 'eval_roc_auc': 0.6124494821924727, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.308, 'eval_steps_per_second': 20.817, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090254545211792, 'eval_roc_auc': 0.6124179085627683, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.548, 'eval_steps_per_second': 20.825, 'epoch': 0.77}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509025514125824, 'eval_roc_auc': 0.6124679001431338, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.381, 'eval_steps_per_second': 20.82, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090256333351135, 'eval_roc_auc': 0.6124547444640902, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.031, 'eval_steps_per_second': 20.84, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090258121490479, 'eval_roc_auc': 0.6124705312789425, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.578, 'eval_steps_per_second': 20.826, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090259313583374, 'eval_roc_auc': 0.6124968426370295, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.615, 'eval_steps_per_second': 20.763, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509026050567627, 'eval_roc_auc': 0.6124915803654122, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.942, 'eval_steps_per_second': 20.805, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090262293815613, 'eval_roc_auc': 0.6125178917234992, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.335, 'eval_steps_per_second': 20.818, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090264081954956, 'eval_roc_auc': 0.6125494653532038, 'eval_runtime': 6.0398, 'eval_samples_per_second': 144.377, 'eval_steps_per_second': 4.636, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090265274047852, 'eval_roc_auc': 0.6125126294518818, 'eval_runtime': 1.3378, 'eval_samples_per_second': 651.793, 'eval_steps_per_second': 20.929, 'epoch': 0.78}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090266466140747, 'eval_roc_auc': 0.6125547276248211, 'eval_runtime': 1.3411, 'eval_samples_per_second': 650.234, 'eval_steps_per_second': 20.879, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090267658233643, 'eval_roc_auc': 0.6125968257977604, 'eval_runtime': 1.3412, 'eval_samples_per_second': 650.16, 'eval_steps_per_second': 20.877, 'epoch': 0.79}
before update
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090268850326538, 'eval_roc_auc': 0.6126310305632735, 'eval_runtime': 1.3409, 'eval_samples_per_second': 650.307, 'eval_steps_per_second': 20.881, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090270638465881, 'eval_roc_auc': 0.6126283994274648, 'eval_runtime': 1.3411, 'eval_samples_per_second': 650.223, 'eval_steps_per_second': 20.879, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090271234512329, 'eval_roc_auc': 0.6126547107855519, 'eval_runtime': 1.342, 'eval_samples_per_second': 649.793, 'eval_steps_per_second': 20.865, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090273022651672, 'eval_roc_auc': 0.6126441862423171, 'eval_runtime': 1.3651, 'eval_samples_per_second': 638.777, 'eval_steps_per_second': 20.511, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090274214744568, 'eval_roc_auc': 0.6127178580449608, 'eval_runtime': 1.3566, 'eval_samples_per_second': 642.778, 'eval_steps_per_second': 20.64, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090276002883911, 'eval_roc_auc': 0.6127441694030479, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.802, 'eval_steps_per_second': 20.833, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 79%|███████▉  | 740/931 [18:26<04:45,  1.50s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▉  | 740/931 [18:26<04:45,  1.50s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090277194976807, 'eval_roc_auc': 0.6128178412056917, 'eval_runtime': 1.3413, 'eval_samples_per_second': 650.105, 'eval_steps_per_second': 20.875, 'epoch': 0.79}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090280175209045, 'eval_roc_auc': 0.6129283489096573, 'eval_runtime': 1.3422, 'eval_samples_per_second': 649.69, 'eval_steps_per_second': 20.862, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090280771255493, 'eval_roc_auc': 0.6129599225393617, 'eval_runtime': 1.3517, 'eval_samples_per_second': 645.133, 'eval_steps_per_second': 20.715, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090282559394836, 'eval_roc_auc': 0.6130388566136229, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.306, 'eval_steps_per_second': 20.817, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090283751487732, 'eval_roc_auc': 0.613091479329797, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.209, 'eval_steps_per_second': 20.846, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090284943580627, 'eval_roc_auc': 0.6131230529595015, 'eval_runtime': 1.3428, 'eval_samples_per_second': 649.367, 'eval_steps_per_second': 20.851, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090285539627075, 'eval_roc_auc': 0.6131862002189106, 'eval_runtime': 1.3449, 'eval_samples_per_second': 648.391, 'eval_steps_per_second': 20.82, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090286731719971, 'eval_roc_auc': 0.6132282983918498, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.662, 'eval_steps_per_second': 20.796, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090288519859314, 'eval_roc_auc': 0.613244085206702, 'eval_runtime': 1.3435, 'eval_samples_per_second': 649.065, 'eval_steps_per_second': 20.842, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509028971195221, 'eval_roc_auc': 0.6132282983918498, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.428, 'eval_steps_per_second': 20.821, 'epoch': 0.8}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090290904045105, 'eval_roc_auc': 0.6132967079228762, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.939, 'eval_steps_per_second': 20.805, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090292692184448, 'eval_roc_auc': 0.6133756419971372, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.29, 'eval_steps_per_second': 20.785, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090294480323792, 'eval_roc_auc': 0.6133887976761808, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.697, 'eval_steps_per_second': 20.83, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090295076370239, 'eval_roc_auc': 0.613423002441694, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.566, 'eval_steps_per_second': 20.826, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090296864509583, 'eval_roc_auc': 0.6134756251578681, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.718, 'eval_steps_per_second': 20.83, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.509029746055603, 'eval_roc_auc': 0.6135492969605119, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.562, 'eval_steps_per_second': 20.858, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 81%|████████▏ | 758/931 [18:52<04:11,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 81%|████████▏ | 758/931 [18:52<04:11,  1.45s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090298652648926, 'eval_roc_auc': 0.6136071819483033, 'eval_runtime': 1.343, 'eval_samples_per_second': 649.294, 'eval_steps_per_second': 20.849, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090299844741821, 'eval_roc_auc': 0.6135756083185989, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.119, 'eval_steps_per_second': 20.811, 'epoch': 0.81}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090301036834717, 'eval_roc_auc': 0.6136598046644776, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.525, 'eval_steps_per_second': 20.824, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090302228927612, 'eval_roc_auc': 0.613754525553591, 'eval_runtime': 1.3442, 'eval_samples_per_second': 648.733, 'eval_steps_per_second': 20.831, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509030282497406, 'eval_roc_auc': 0.613780836911678, 'eval_runtime': 1.3427, 'eval_samples_per_second': 649.444, 'eval_steps_per_second': 20.854, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090304017066956, 'eval_roc_auc': 0.6138597709859392, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.948, 'eval_steps_per_second': 20.806, 'epoch': 0.82}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090305209159851, 'eval_roc_auc': 0.6139123937021133, 'eval_runtime': 1.3572, 'eval_samples_per_second': 642.522, 'eval_steps_per_second': 20.631, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090306401252747, 'eval_roc_auc': 0.6139439673318177, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.95, 'eval_steps_per_second': 20.806, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090306997299194, 'eval_roc_auc': 0.6139544918750526, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.256, 'eval_steps_per_second': 20.816, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509030818939209, 'eval_roc_auc': 0.6139860655047571, 'eval_runtime': 1.3784, 'eval_samples_per_second': 632.635, 'eval_steps_per_second': 20.314, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090309381484985, 'eval_roc_auc': 0.6140334259493138, 'eval_runtime': 1.3698, 'eval_samples_per_second': 636.582, 'eval_steps_per_second': 20.441, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090310573577881, 'eval_roc_auc': 0.6141097288877662, 'eval_runtime': 1.3553, 'eval_samples_per_second': 643.384, 'eval_steps_per_second': 20.659, 'epoch': 0.82}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090311765670776, 'eval_roc_auc': 0.6142070809126884, 'eval_runtime': 1.3511, 'eval_samples_per_second': 645.396, 'eval_steps_per_second': 20.724, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090312361717224, 'eval_roc_auc': 0.6142412856782016, 'eval_runtime': 1.3757, 'eval_samples_per_second': 633.869, 'eval_steps_per_second': 20.354, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090312957763672, 'eval_roc_auc': 0.6142228677275405, 'eval_runtime': 1.3633, 'eval_samples_per_second': 639.637, 'eval_steps_per_second': 20.539, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090318918228149, 'eval_roc_auc': 0.6146228003704639, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.659, 'eval_steps_per_second': 20.828, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090324282646179, 'eval_roc_auc': 0.6149385366675085, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.195, 'eval_steps_per_second': 20.814, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090328454971313, 'eval_roc_auc': 0.6152858465942578, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.859, 'eval_steps_per_second': 20.803, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090332627296448, 'eval_roc_auc': 0.6158436473857034, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.96, 'eval_steps_per_second': 20.806, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 83%|████████▎ | 776/931 [19:20<03:46,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 83%|████████▎ | 776/931 [19:20<03:46,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090336203575134, 'eval_roc_auc': 0.6160936052875304, 'eval_runtime': 1.3621, 'eval_samples_per_second': 640.202, 'eval_steps_per_second': 20.557, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090339183807373, 'eval_roc_auc': 0.6163277763745054, 'eval_runtime': 1.3527, 'eval_samples_per_second': 644.627, 'eval_steps_per_second': 20.699, 'epoch': 0.83}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 83%|████████▎ | 776/931 [19:20<03:46,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090341567993164, 'eval_roc_auc': 0.6164909067946451, 'eval_runtime': 1.361, 'eval_samples_per_second': 640.704, 'eval_steps_per_second': 20.573, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090343952178955, 'eval_roc_auc': 0.6167013976593415, 'eval_runtime': 1.3547, 'eval_samples_per_second': 643.698, 'eval_steps_per_second': 20.669, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090346932411194, 'eval_roc_auc': 0.6168119053633072, 'eval_runtime': 1.3523, 'eval_samples_per_second': 644.831, 'eval_steps_per_second': 20.706, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090348720550537, 'eval_roc_auc': 0.6168382167213943, 'eval_runtime': 1.3535, 'eval_samples_per_second': 644.243, 'eval_steps_per_second': 20.687, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090351700782776, 'eval_roc_auc': 0.6172328870927002, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.277, 'eval_steps_per_second': 20.816, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090354681015015, 'eval_roc_auc': 0.6176512376862844, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.215, 'eval_steps_per_second': 20.814, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090357065200806, 'eval_roc_auc': 0.6178854087732593, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.58, 'eval_steps_per_second': 20.826, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090359449386597, 'eval_roc_auc': 0.6180853750947208, 'eval_runtime': 1.3551, 'eval_samples_per_second': 643.514, 'eval_steps_per_second': 20.663, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509036123752594, 'eval_roc_auc': 0.6184011113917656, 'eval_runtime': 1.3595, 'eval_samples_per_second': 641.403, 'eval_steps_per_second': 20.595, 'epoch': 0.84}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 85%|████████▍ | 787/931 [19:36<03:30,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 85%|████████▍ | 787/931 [19:36<03:30,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090363621711731, 'eval_roc_auc': 0.6187431590468973, 'eval_runtime': 1.3683, 'eval_samples_per_second': 637.272, 'eval_steps_per_second': 20.463, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 85%|████████▍ | 787/931 [19:36<03:30,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090365409851074, 'eval_roc_auc': 0.6187931506272627, 'eval_runtime': 1.4009, 'eval_samples_per_second': 622.472, 'eval_steps_per_second': 19.988, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509036660194397, 'eval_roc_auc': 0.6190694198871768, 'eval_runtime': 1.3795, 'eval_samples_per_second': 632.092, 'eval_steps_per_second': 20.297, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 85%|████████▍ | 787/931 [19:36<03:30,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090367794036865, 'eval_roc_auc': 0.6192799107518733, 'eval_runtime': 1.3992, 'eval_samples_per_second': 623.21, 'eval_steps_per_second': 20.011, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 85%|████████▌ | 792/931 [19:42<03:26,  1.48s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 85%|████████▌ | 792/931 [19:42<03:26,  1.48s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090368986129761, 'eval_roc_auc': 0.619390418455839, 'eval_runtime': 1.3478, 'eval_samples_per_second': 646.999, 'eval_steps_per_second': 20.775, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090371370315552, 'eval_roc_auc': 0.6196482697650922, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.747, 'eval_steps_per_second': 20.799, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090371966362, 'eval_roc_auc': 0.6197693020122926, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.328, 'eval_steps_per_second': 20.818, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090373158454895, 'eval_roc_auc': 0.6198587606297887, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.305, 'eval_steps_per_second': 20.785, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090373754501343, 'eval_roc_auc': 0.6198850719878756, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.697, 'eval_steps_per_second': 20.798, 'epoch': 0.85}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509037435054779, 'eval_roc_auc': 0.6199850551486065, 'eval_runtime': 1.3475, 'eval_samples_per_second': 647.115, 'eval_steps_per_second': 20.779, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090374946594238, 'eval_roc_auc': 0.6200218910499284, 'eval_runtime': 1.3583, 'eval_samples_per_second': 641.975, 'eval_steps_per_second': 20.614, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090375542640686, 'eval_roc_auc': 0.6200587269512503, 'eval_runtime': 1.3712, 'eval_samples_per_second': 635.946, 'eval_steps_per_second': 20.42, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.6201481855687463, 'eval_runtime': 1.3821, 'eval_samples_per_second': 630.936, 'eval_steps_per_second': 20.259, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090376734733582, 'eval_roc_auc': 0.6201166119390418, 'eval_runtime': 1.4319, 'eval_samples_per_second': 608.973, 'eval_steps_per_second': 19.554, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 86%|████████▌ | 802/931 [19:58<03:12,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 86%|████████▌ | 802/931 [19:58<03:12,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090377330780029, 'eval_roc_auc': 0.6201113496674244, 'eval_runtime': 1.3888, 'eval_samples_per_second': 627.887, 'eval_steps_per_second': 20.162, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 86%|████████▌ | 802/931 [19:58<03:12,  1.49s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090377926826477, 'eval_roc_auc': 0.6201797591984508, 'eval_runtime': 1.3568, 'eval_samples_per_second': 642.684, 'eval_steps_per_second': 20.637, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.6202060705565378, 'eval_runtime': 1.4667, 'eval_samples_per_second': 594.529, 'eval_steps_per_second': 19.09, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.6202376441862423, 'eval_runtime': 1.3709, 'eval_samples_per_second': 636.059, 'eval_steps_per_second': 20.424, 'epoch': 0.86}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 87%|████████▋ | 806/931 [20:04<03:08,  1.51s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 87%|████████▋ | 806/931 [20:04<03:08,  1.51s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090379118919373, 'eval_roc_auc': 0.6202455375936684, 'eval_runtime': 1.3799, 'eval_samples_per_second': 631.938, 'eval_steps_per_second': 20.292, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 87%|████████▋ | 806/931 [20:04<03:08,  1.51s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509037971496582, 'eval_roc_auc': 0.6203165782605035, 'eval_runtime': 1.3612, 'eval_samples_per_second': 640.618, 'eval_steps_per_second': 20.57, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090380311012268, 'eval_roc_auc': 0.6203376273469732, 'eval_runtime': 1.3707, 'eval_samples_per_second': 636.17, 'eval_steps_per_second': 20.427, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090380907058716, 'eval_roc_auc': 0.6203586764334428, 'eval_runtime': 1.3691, 'eval_samples_per_second': 636.934, 'eval_steps_per_second': 20.452, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090380907058716, 'eval_roc_auc': 0.6204323482360865, 'eval_runtime': 1.3648, 'eval_samples_per_second': 638.944, 'eval_steps_per_second': 20.517, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090380907058716, 'eval_roc_auc': 0.6204797086806433, 'eval_runtime': 1.3526, 'eval_samples_per_second': 644.674, 'eval_steps_per_second': 20.701, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090381503105164, 'eval_roc_auc': 0.6204849709522606, 'eval_runtime': 1.3871, 'eval_samples_per_second': 628.652, 'eval_steps_per_second': 20.186, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090381503105164, 'eval_roc_auc': 0.6205270691252, 'eval_runtime': 1.3824, 'eval_samples_per_second': 630.779, 'eval_steps_per_second': 20.254, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090382099151611, 'eval_roc_auc': 0.6205428559400522, 'eval_runtime': 1.3644, 'eval_samples_per_second': 639.109, 'eval_steps_per_second': 20.522, 'epoch': 0.87}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090382695198059, 'eval_roc_auc': 0.620516544581965, 'eval_runtime': 1.3681, 'eval_samples_per_second': 637.361, 'eval_steps_per_second': 20.466, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090382695198059, 'eval_roc_auc': 0.6205191757177738, 'eval_runtime': 1.3701, 'eval_samples_per_second': 636.448, 'eval_steps_per_second': 20.436, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090383291244507, 'eval_roc_auc': 0.6205218068535826, 'eval_runtime': 1.3552, 'eval_samples_per_second': 643.442, 'eval_steps_per_second': 20.661, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090383291244507, 'eval_roc_auc': 0.6205112823103478, 'eval_runtime': 1.3472, 'eval_samples_per_second': 647.265, 'eval_steps_per_second': 20.784, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.6205744295697566, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.449, 'eval_steps_per_second': 20.822, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090383887290955, 'eval_roc_auc': 0.6205796918413742, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.89, 'eval_steps_per_second': 20.836, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090384483337402, 'eval_roc_auc': 0.6205823229771829, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.674, 'eval_steps_per_second': 20.797, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090384483337402, 'eval_roc_auc': 0.6205796918413741, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.141, 'eval_steps_per_second': 20.844, 'epoch': 0.88}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090384483337402, 'eval_roc_auc': 0.6206217900143134, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.334, 'eval_steps_per_second': 20.786, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.6206375768291656, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.474, 'eval_steps_per_second': 20.823, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509038507938385, 'eval_roc_auc': 0.6206060031994611, 'eval_runtime': 1.3503, 'eval_samples_per_second': 645.76, 'eval_steps_per_second': 20.735, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.620616527742696, 'eval_runtime': 1.3447, 'eval_samples_per_second': 648.492, 'eval_steps_per_second': 20.823, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.6206270522859307, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.733, 'eval_steps_per_second': 20.799, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 89%|████████▉ | 829/931 [20:38<02:28,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 89%|████████▉ | 829/931 [20:38<02:28,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.6206375768291656, 'eval_runtime': 1.3434, 'eval_samples_per_second': 649.122, 'eval_steps_per_second': 20.843, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090385675430298, 'eval_roc_auc': 0.6206691504588702, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.726, 'eval_steps_per_second': 20.799, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 89%|████████▉ | 829/931 [20:38<02:28,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386271476746, 'eval_roc_auc': 0.6206849372737224, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.887, 'eval_steps_per_second': 20.804, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.6206849372737223, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.884, 'eval_steps_per_second': 20.772, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.620724404310853, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.632, 'eval_steps_per_second': 20.796, 'epoch': 0.89}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.6207112486318094, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.749, 'eval_steps_per_second': 20.799, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090386867523193, 'eval_roc_auc': 0.6206901995453398, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.269, 'eval_steps_per_second': 20.816, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.6207691336196008, 'eval_runtime': 1.344, 'eval_samples_per_second': 648.823, 'eval_steps_per_second': 20.834, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.6208059695209228, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.614, 'eval_steps_per_second': 20.827, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.6208270186073924, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.693, 'eval_steps_per_second': 20.797, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090387463569641, 'eval_roc_auc': 0.6208007072493054, 'eval_runtime': 1.3514, 'eval_samples_per_second': 645.241, 'eval_steps_per_second': 20.719, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 90%|█████████ | 841/931 [20:54<02:11,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 90%|█████████ | 841/931 [20:54<02:11,  1.46s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6207901827060704, 'eval_runtime': 1.3541, 'eval_samples_per_second': 643.968, 'eval_steps_per_second': 20.678, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6207901827060706, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.873, 'eval_steps_per_second': 20.771, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6208059695209228, 'eval_runtime': 1.3463, 'eval_samples_per_second': 647.701, 'eval_steps_per_second': 20.798, 'epoch': 0.9}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6208007072493054, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.822, 'eval_steps_per_second': 20.802, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6207691336196008, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.856, 'eval_steps_per_second': 20.803, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6207849204344531, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.342, 'eval_steps_per_second': 20.786, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090388655662537, 'eval_roc_auc': 0.6207980761134967, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.912, 'eval_steps_per_second': 20.805, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090389251708984, 'eval_roc_auc': 0.6208112317925402, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.911, 'eval_steps_per_second': 20.804, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090389847755432, 'eval_roc_auc': 0.6208270186073925, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.755, 'eval_steps_per_second': 20.799, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090389847755432, 'eval_roc_auc': 0.620884903595184, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.405, 'eval_steps_per_second': 20.82, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090389847755432, 'eval_roc_auc': 0.6209006904100363, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.512, 'eval_steps_per_second': 20.824, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.509039044380188, 'eval_roc_auc': 0.6209164772248885, 'eval_runtime': 1.3454, 'eval_samples_per_second': 648.124, 'eval_steps_per_second': 20.811, 'epoch': 0.91}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.6209585753978277, 'eval_runtime': 1.3487, 'eval_samples_per_second': 646.526, 'eval_steps_per_second': 20.76, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.6210111981140019, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.914, 'eval_steps_per_second': 20.805, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.6210217226572368, 'eval_runtime': 1.3474, 'eval_samples_per_second': 647.159, 'eval_steps_per_second': 20.78, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.6210401406078977, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.888, 'eval_steps_per_second': 20.772, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.6210427717437065, 'eval_runtime': 1.3456, 'eval_samples_per_second': 648.028, 'eval_steps_per_second': 20.808, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090391039848328, 'eval_roc_auc': 0.621082238780837, 'eval_runtime': 1.3471, 'eval_samples_per_second': 647.335, 'eval_steps_per_second': 20.786, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 92%|█████████▏| 858/931 [21:20<01:46,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 92%|█████████▏| 858/931 [21:20<01:46,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090391635894775, 'eval_roc_auc': 0.6210743453734109, 'eval_runtime': 1.3504, 'eval_samples_per_second': 645.742, 'eval_steps_per_second': 20.735, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090391635894775, 'eval_roc_auc': 0.6210743453734108, 'eval_runtime': 1.349, 'eval_samples_per_second': 646.391, 'eval_steps_per_second': 20.756, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090391635894775, 'eval_roc_auc': 0.6210848699166457, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.464, 'eval_steps_per_second': 20.79, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090391635894775, 'eval_roc_auc': 0.6210953944598805, 'eval_runtime': 1.3481, 'eval_samples_per_second': 646.819, 'eval_steps_per_second': 20.769, 'epoch': 0.92}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090392231941223, 'eval_roc_auc': 0.6211217058179674, 'eval_runtime': 1.3756, 'eval_samples_per_second': 633.918, 'eval_steps_per_second': 20.355, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090392231941223, 'eval_roc_auc': 0.621082238780837, 'eval_runtime': 1.3486, 'eval_samples_per_second': 646.582, 'eval_steps_per_second': 20.762, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090392231941223, 'eval_roc_auc': 0.6210585585585586, 'eval_runtime': 1.3458, 'eval_samples_per_second': 647.943, 'eval_steps_per_second': 20.806, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090392827987671, 'eval_roc_auc': 0.6211217058179674, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.671, 'eval_steps_per_second': 20.797, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090392827987671, 'eval_roc_auc': 0.6211322303612024, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.189, 'eval_steps_per_second': 20.813, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090392827987671, 'eval_roc_auc': 0.621153279447672, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.537, 'eval_steps_per_second': 20.792, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090392827987671, 'eval_roc_auc': 0.6211427549044372, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.579, 'eval_steps_per_second': 20.826, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090393424034119, 'eval_roc_auc': 0.6211111812747327, 'eval_runtime': 1.3452, 'eval_samples_per_second': 648.253, 'eval_steps_per_second': 20.815, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090393424034119, 'eval_roc_auc': 0.6211690662625242, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.32, 'eval_steps_per_second': 20.818, 'epoch': 0.93}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090393424034119, 'eval_roc_auc': 0.6211743285341417, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.16, 'eval_steps_per_second': 20.845, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090394020080566, 'eval_roc_auc': 0.6212269512503157, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.868, 'eval_steps_per_second': 20.835, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090394616127014, 'eval_roc_auc': 0.6212216889786984, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.91, 'eval_steps_per_second': 20.804, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090394616127014, 'eval_roc_auc': 0.6212637871516377, 'eval_runtime': 1.348, 'eval_samples_per_second': 646.879, 'eval_steps_per_second': 20.771, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212532626084029, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.89, 'eval_steps_per_second': 20.836, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212348446577419, 'eval_runtime': 6.1218, 'eval_samples_per_second': 142.442, 'eval_steps_per_second': 4.574, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212822051022986, 'eval_runtime': 1.3383, 'eval_samples_per_second': 651.596, 'eval_steps_per_second': 20.923, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212427380651682, 'eval_runtime': 1.341, 'eval_samples_per_second': 650.276, 'eval_steps_per_second': 20.88, 'epoch': 0.94}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212111644354635, 'eval_runtime': 1.3464, 'eval_samples_per_second': 647.666, 'eval_steps_per_second': 20.797, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090395212173462, 'eval_roc_auc': 0.6212111644354635, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.684, 'eval_steps_per_second': 20.829, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 95%|█████████▍| 883/931 [22:00<01:17,  1.62s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 95%|█████████▍| 883/931 [22:00<01:17,  1.62s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.509039580821991, 'eval_roc_auc': 0.6212295823861246, 'eval_runtime': 1.3461, 'eval_samples_per_second': 647.773, 'eval_steps_per_second': 20.8, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509039580821991, 'eval_roc_auc': 0.6212216889786983, 'eval_runtime': 1.3414, 'eval_samples_per_second': 650.062, 'eval_steps_per_second': 20.874, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`dding tokens in conjunction with `inputs_embeds.`
{'eval_loss': 0.5090396404266357, 'eval_roc_auc': 0.6213111475961943, 'eval_runtime': 1.3414, 'eval_samples_per_second': 650.068, 'eval_steps_per_second': 20.874, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397000312805, 'eval_roc_auc': 0.6213690325839859, 'eval_runtime': 1.3425, 'eval_samples_per_second': 649.521, 'eval_steps_per_second': 20.856, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397000312805, 'eval_roc_auc': 0.6213742948556032, 'eval_runtime': 1.34, 'eval_samples_per_second': 650.741, 'eval_steps_per_second': 20.895, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090397000312805, 'eval_roc_auc': 0.6214058684853078, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.595, 'eval_steps_per_second': 20.859, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397000312805, 'eval_roc_auc': 0.621376925991412, 'eval_runtime': 1.3412, 'eval_samples_per_second': 650.184, 'eval_steps_per_second': 20.877, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397596359253, 'eval_roc_auc': 0.6214006062136904, 'eval_runtime': 1.3426, 'eval_samples_per_second': 649.476, 'eval_steps_per_second': 20.855, 'epoch': 0.95}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090397596359253, 'eval_roc_auc': 0.6214269175717775, 'eval_runtime': 1.343, 'eval_samples_per_second': 649.301, 'eval_steps_per_second': 20.849, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397596359253, 'eval_roc_auc': 0.6214637534730992, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.965, 'eval_steps_per_second': 20.838, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397596359253, 'eval_roc_auc': 0.6214584912014819, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.605, 'eval_steps_per_second': 20.859, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090397596359253, 'eval_roc_auc': 0.6215005893744211, 'eval_runtime': 1.3421, 'eval_samples_per_second': 649.751, 'eval_steps_per_second': 20.864, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6214953271028039, 'eval_runtime': 1.342, 'eval_samples_per_second': 649.753, 'eval_steps_per_second': 20.864, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215742611770649, 'eval_runtime': 1.343, 'eval_samples_per_second': 649.315, 'eval_steps_per_second': 20.85, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215742611770649, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.559, 'eval_steps_per_second': 20.825, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215847857202997, 'eval_runtime': 1.3466, 'eval_samples_per_second': 647.556, 'eval_steps_per_second': 20.793, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215742611770648, 'eval_runtime': 1.3424, 'eval_samples_per_second': 649.592, 'eval_steps_per_second': 20.858, 'epoch': 0.96}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215689989054474, 'eval_runtime': 1.3439, 'eval_samples_per_second': 648.857, 'eval_steps_per_second': 20.835, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090398788452148, 'eval_roc_auc': 0.6215847857202997, 'eval_runtime': 1.3423, 'eval_samples_per_second': 649.651, 'eval_steps_per_second': 20.86, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090399384498596, 'eval_roc_auc': 0.6216110970783868, 'eval_runtime': 1.3432, 'eval_samples_per_second': 649.208, 'eval_steps_per_second': 20.846, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090399384498596, 'eval_roc_auc': 0.6215953102635345, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.905, 'eval_steps_per_second': 20.836, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090399384498596, 'eval_roc_auc': 0.6215847857202998, 'eval_runtime': 1.3446, 'eval_samples_per_second': 648.51, 'eval_steps_per_second': 20.824, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090399980545044, 'eval_roc_auc': 0.6215689989054474, 'eval_runtime': 1.3429, 'eval_samples_per_second': 649.348, 'eval_steps_per_second': 20.851, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090399980545044, 'eval_roc_auc': 0.6216137282141956, 'eval_runtime': 1.3438, 'eval_samples_per_second': 648.92, 'eval_steps_per_second': 20.837, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090399980545044, 'eval_roc_auc': 0.6216216216216217, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.081, 'eval_steps_per_second': 20.81, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 97%|█████████▋| 907/931 [22:36<00:34,  1.45s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 97%|█████████▋| 907/931 [22:36<00:34,  1.45s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090400576591492, 'eval_roc_auc': 0.6216374084364739, 'eval_runtime': 1.3462, 'eval_samples_per_second': 647.76, 'eval_steps_per_second': 20.8, 'epoch': 0.97}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
 97%|█████████▋| 907/931 [22:36<00:34,  1.45s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090400576591492, 'eval_roc_auc': 0.6216821377452219, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.269, 'eval_steps_per_second': 20.816, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509040117263794, 'eval_roc_auc': 0.6217321293255873, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.639, 'eval_steps_per_second': 20.828, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509040117263794, 'eval_roc_auc': 0.6218215879430833, 'eval_runtime': 1.3465, 'eval_samples_per_second': 647.608, 'eval_steps_per_second': 20.795, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509040117263794, 'eval_roc_auc': 0.6218110633998485, 'eval_runtime': 1.3459, 'eval_samples_per_second': 647.883, 'eval_steps_per_second': 20.804, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509040117263794, 'eval_roc_auc': 0.6218478993011705, 'eval_runtime': 1.3433, 'eval_samples_per_second': 649.16, 'eval_steps_per_second': 20.845, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218478993011703, 'eval_runtime': 1.3448, 'eval_samples_per_second': 648.412, 'eval_steps_per_second': 20.821, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218531615727878, 'eval_runtime': 1.3455, 'eval_samples_per_second': 648.108, 'eval_steps_per_second': 20.811, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218742106592574, 'eval_runtime': 1.3477, 'eval_samples_per_second': 647.044, 'eval_steps_per_second': 20.777, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218478993011703, 'eval_runtime': 1.3437, 'eval_samples_per_second': 648.944, 'eval_steps_per_second': 20.838, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218636861160226, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.547, 'eval_steps_per_second': 20.825, 'epoch': 0.98}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`_embeds.`.`
{'eval_loss': 0.5090401768684387, 'eval_roc_auc': 0.6218215879430833, 'eval_runtime': 1.3445, 'eval_samples_per_second': 648.569, 'eval_steps_per_second': 20.826, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219057842889618, 'eval_runtime': 1.3461, 'eval_samples_per_second': 647.774, 'eval_steps_per_second': 20.8, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will notGPT2ForSeGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219373579186663, 'eval_runtime': 1.3443, 'eval_samples_per_second': 648.686, 'eval_steps_per_second': 20.829, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219215711038142, 'eval_runtime': 1.3513, 'eval_samples_per_second': 645.293, 'eval_steps_per_second': 20.72, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219242022396227, 'eval_runtime': 1.3467, 'eval_samples_per_second': 647.49, 'eval_steps_per_second': 20.791, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219478824619011, 'eval_runtime': 1.3474, 'eval_samples_per_second': 647.185, 'eval_steps_per_second': 20.781, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090402960777283, 'eval_roc_auc': 0.6219373579186663, 'eval_runtime': 1.3501, 'eval_samples_per_second': 645.878, 'eval_steps_per_second': 20.739, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
 99%|█████████▉| 926/931 [23:04<00:07,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 99%|█████████▉| 926/931 [23:04<00:07,  1.46s/iGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509040355682373, 'eval_roc_auc': 0.6219610381409446, 'eval_runtime': 1.3468, 'eval_samples_per_second': 647.445, 'eval_steps_per_second': 20.79, 'epoch': 0.99}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.509040355682373, 'eval_roc_auc': 0.6220110297213102, 'eval_runtime': 1.347, 'eval_samples_per_second': 647.384, 'eval_steps_per_second': 20.788, 'epoch': 1.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.509040355682373, 'eval_roc_auc': 0.6220189231287362, 'eval_runtime': 1.345, 'eval_samples_per_second': 648.336, 'eval_steps_per_second': 20.818, 'epoch': 1.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`.`
{'eval_loss': 0.5090404152870178, 'eval_roc_auc': 0.6220268165361623, 'eval_runtime': 1.3453, 'eval_samples_per_second': 648.186, 'eval_steps_per_second': 20.813, 'epoch': 1.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``.`
{'eval_loss': 0.5090404152870178, 'eval_roc_auc': 0.6220110297213102, 'eval_runtime': 1.3444, 'eval_samples_per_second': 648.623, 'eval_steps_per_second': 20.827, 'epoch': 1.0}
before update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
after update
tensor([0.8823], device='cuda:0')
tensor([1.], device='cuda:0')
tensor([0.], device='cuda:0')
{'eval_loss': 0.5090404152870178, 'eval_roc_auc': 0.6220320788077798, 'eval_runtime': 1.346, 'eval_samples_per_second': 647.86, 'eval_steps_per_second': 20.803, 'epoch': 1.0}
 46%|████▋     | 13/28 [00:00<00:00, 21.50it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
 46%|████▋     | 13/28 [00:00<00:00, 21.50it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`.`
balanced data AUC after train
 {'eval_loss': 0.5090360045433044, 'eval_roc_auc': 0.5705723246611097, 'eval_runtime': 1.3451, 'eval_samples_per_second': 648.259, 'eval_steps_per_second': 20.816, 'epoch': 1.0}